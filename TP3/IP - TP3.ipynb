{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "<div style=\"text-align:center\"> \n",
    "\n",
    "***\n",
    "# <u>TP3:</u>\n",
    "# Bruit et Opérations morhpologiques\n",
    "    \n",
    "<p style=\"text-align: center; color:gray\"><i>@Author:</i> Marc-Aurèle Rivière</p>\n",
    "\n",
    "***\n",
    "        \n",
    "</div>\n",
    "    \n",
    "<u>**Plan:**</u>\n",
    "\n",
    "1. [**Bruit et Débruitage**](#1)\n",
    "2. [**Opérations morphologiques**](#2): \n",
    "    1. Erosion & Dilatations\n",
    "    2. Ouverture & Fermetures\n",
    "    3. Hit-or-Miss\n",
    "    4. Thinning & Thickening\n",
    "    5. Skeletonization\n",
    "    6. Convex Hull\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"1\">I. Bruit et Débruitage</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.1 Bruit</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En traitement du signal (et donc par extension, des images), le **bruit** fait référence à des variations aléatoires \"non-expliquées\" du signal (et donc de la luminance ou couleur des pixels dans notre cas). Ce bruit est donc une dégradation de l'image par rapport à un état d'origine, ou un état optimal espéré.\n",
    "\n",
    "**Ajouter du bruit** à une image revient donc à modifier la valeur de luminance (ou chrominance) de certains pixels par des valeurs \"aléatoires\". En réalité, le bruit observé dans les systèmes électroniques n'est pas aléatoire, mais dépends de processus génératifs qui ne sont pas connus / compris, et est donc considéré / modélisé comme aléatoire. Ce bruit peut  provenir de plusieurs sources: mauvais capteurs, trop faible luminosité lors de la prise de l'image, problèmes d'électronique, dégradation du support de stockage de l'image avec le temps, ...\n",
    "  \n",
    "On distingue deux grandes catégories de bruits:\n",
    "\n",
    "### I.1.a Bruits additifs :\n",
    "\n",
    "Le niveau de bruit est indépendant de la valeur du signal: chaque pixel est uniformément susceptibles d'être bruité. Il n'y à donc pas d'intéraction entre le bruit et le signal.\n",
    "\n",
    "$I'(x,y) = I(x,y) + \\eta(x,y)$\n",
    "\n",
    "<u>Exemples de bruits additifs</u>: Gaussian, ...\n",
    "\n",
    "Les **filtres linéaires** sont efficaces pour retirer les bruits additifis.\n",
    "\n",
    "### I.1.b Bruits multiplicatifs :\n",
    "\n",
    "Le niveau de bruit dépends / est corrélé à la valeur du signal: certains pixels seront plus susceptibles d'être bruités selon leur valeur. On peut parler d'interaction entre le bruit et le signal.\n",
    "\n",
    "<u>Exemples de bruits multiplicatifs</u>: Salt, Pepper, Salt&Pepper, Speckle, Poisson, ...\n",
    "\n",
    "Le **filtre médian** et les **opération morphologiques** sont efficaces pour retirer les bruits multiplicatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, interact_manual\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Fonction d'affichage utilisant OpenCV pour calculer l'histogramme de l'image\n",
    "def affichage_2x2(img1, img2, c=\"gray\"):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, c)\n",
    "    ax1.set_title(\"Image originale\", color='b')\n",
    "    ax2 = plt.subplot(222)\n",
    "    ax2.hist(img1.ravel(), 256, [0,256])\n",
    "    ax2.set_title(\"Histogramme de l'image originale\", color='b')\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, c)\n",
    "    ax3.set_title(\"Image bruitée\", color='c')\n",
    "    ax4 = plt.subplot(224, sharex=ax2, sharey=ax2)\n",
    "    ax4.hist(img2.ravel(), 256, [0,256])\n",
    "    ax4.set_title(\"Histogramme de l'image bruitée\", color='c')\n",
    "    plt.show()\n",
    "\n",
    "# Affichons l'image originale, modifiée, et leurs histogrames (*smoothed* via un KDE - Kernel Density Estimation)\n",
    "def affichage_2x2_smoothed(img1, img2):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, \"gray\")\n",
    "    ax1.set_title(\"Image originale\")\n",
    "    ax2 = plt.subplot(222)\n",
    "    sns.kdeplot(np.array(img1).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,256], cut=0)\n",
    "    ax2.set_title(\"Histogramme (KDE) de l'original\")\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, \"gray\")\n",
    "    ax3.set_title(\"Image bruitée\")\n",
    "    ax4 = plt.subplot(224, sharex=ax2, sharey=ax2)\n",
    "    sns.kdeplot(np.array(img2).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,256], cut=0)\n",
    "    ax4.set_title(\"Histogramme (KDE) de l'image bruitée\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.a Bruit Gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **bruit gaussien** est un **bruit additif** distribué selon une **loi Normale**, ajouté à l'ensemble de l'image. Cela signifie que chaque pixel de l'image va se voir ajouter une valeur piochée aléatoirement dans une distribution Gaussienne :\n",
    "    \n",
    "$X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2})$\n",
    "\n",
    "L'intensité du bruit est lié à la variance $\\sigma^2$ de la distribution utilisée pour modéliser ce bruit. Plus $\\sigma^2$ augmente, plus l'histogramme de l'image bruité se rapprochera d'une loi Normale, le bruit dominant progressivement le signal.\n",
    "\n",
    "La nouvelle intensité de chaque pixel s'exprime par :\n",
    "\n",
    "$I'(x,y) = I(x,y) + \\mathcal{N}(\\mu,\\,\\sigma^{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7239a418ea94510bd1f74a32817d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('barbara.jpg', 'car.png', 'cells.png', 'chest.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def gaussian_noise(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], mean=(-2,2,0.5), var=(0,30,1)):\n",
    "    img = np.array(Image.open('img/' + image).convert(\"L\"))\n",
    "    \n",
    "    # Ajoutons un bruit Gaussien (normal) de moyenne $mean$ et variance $var$\n",
    "    noisy = img + np.random.normal(mean, var, img.shape)\n",
    "    noisy = np.clip(noisy, 0, 255) \n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.b Bruit Salt-and-Pepper (S&P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **bruit de Poisson** (ou *Impulse noise*, ou *Spike noise*) est un **bruit multiplicatif** qui va affecter un certain % de l'image. Cela signifie que chaque pixel de l'image va avoir une certaine chance de passer à 0 (Pepper) ou 255 (Salt), les pixels noirs ayant une plus grande chance de devenir blancs, et vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d550015f134acca148a95caff5f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('barbara.jpg', 'car.png', 'cells.png', 'chest.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def sp_noise(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], sp_amount=(0,1,0.05)):\n",
    "    img = np.array(Image.open('img/' + image).convert(\"L\"))\n",
    "    \n",
    "    # Ajoutons un bruit Gaussien (normal) de moyenne $mean$ et variance $var$\n",
    "    noisy_sp = random_noise(img, mode='s&p', amount=sp_amount)\n",
    "    # The above function returns a floating-point image on the range [0, 1], thus we changed it to 'uint8'\n",
    "    noisy_sp = np.array(255 * noisy_sp, dtype='uint8')\n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.c Poisson noise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **bruit de Poisson** (ou *Shot noise*) est un **bruit multiplicatif** modélisé par une **loi de Poisson**, appliqué à toute l'image. Cela signifie que chaque pixel de l'image va voir sa valeur recalculée selon la loi de Poisson, de moyenne et variance égales à $\\lambda$:\n",
    "\n",
    "$X \\sim \\mathcal P(\\lambda)$, avec $P\\left( x \\right) = \\dfrac{{e^{ - \\lambda } \\lambda ^x }}{{x!}}$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/440px-Poisson_pmf.svg.png\">\n",
    "\n",
    "<u>Remarque</u>: Plus $\\lambda$ est grand, et plus la distribution de Poisson se rapproche d'une loi Normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cc3114d5e4499085d8c1ba44c5d1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('barbara.jpg', 'car.png', 'cells.png', 'chest.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def poisson_noise(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], lambda_const=(0,50,5)):\n",
    "    img = np.array(Image.open('img/' + image).convert(\"L\"))\n",
    "    \n",
    "    noisy = np.random.poisson(img / 255.0 * lambda_const) / lambda_const * 255\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Créez une méthode interactive permettant de choisir l'un des trois types de bruits mentionnés et de l'appliquer à une image couleur.**\n",
    "    \n",
    "    \n",
    "2. **Implémentez deux méthodes permettant de rajouter du bruit *Salt* et *Pepper* séparément.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.2 Débruitage</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif général des méthodes de débruitage est de retrouver au mieux l'image d'origine à partir d'une image bruitée, ce qui nécessite (1) de deviner quels pixels sont bruités, et (2) d'estimer la valeur optimale que ces pixels devraient avoir, en fonction de celles des pixels alentours. On parle **d'interpolation** des valeurs.\n",
    "\n",
    "Estimer le type de bruit auquel le signal est soumis (en fonction des sources suspectées de bruit dans le système) va influencer la stratégie de débruitage à appliquer. De manière général, ces stratégies tentent de déterminer quelles variations d'intensité sont du bruit ou des détails réels (signal) de l'image afin de moyenner/filtrer le bruit tout en préservant les détails.\n",
    "\n",
    "Aucun de ces algorithmes n'est parfait, et ils entraînent souvent une perte d'information dans l'image.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/pagina-personal.appspot.com/img_blog/dual_rof_denoising/gradient_descent_dual_rof.png\" heigth=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Ajout de bruit Gaussien\n",
    "def gaussian_noise(img, mean = 0.0, std = 10.0):\n",
    "    noisy_gauss = img + np.random.normal(mean, std, img.shape)\n",
    "    return np.array(np.clip(noisy_gauss, 0, 255), dtype='uint8')\n",
    "\n",
    "# Ajout de bruit Salt&Pepper\n",
    "def sp_noise(img, prob=0.05):\n",
    "    noisy_sp = random_noise(img, mode='s&p', amount=prob)\n",
    "    # The above function returns a floating-point image on the range [0, 1], thus we changed it to 'uint8'\n",
    "    return np.array(np.clip(noisy_sp, 0, 255), dtype='uint8')\n",
    "\n",
    "def affichage_1x3(img1, img2, img3):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    plt.subplot(131), plt.imshow(img1, cmap='gray'), plt.title(\"Image originale\", color='b')\n",
    "    plt.subplot(132), plt.imshow(img2, cmap='gray'), plt.title(\"Image bruitée\", color='b')\n",
    "    plt.subplot(133), plt.imshow(img3, cmap='gray'), plt.title(\"Image débruitée\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour une image en noir et blanc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avec OpenCV:**\n",
    "```Python\n",
    "imgDenoised = cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n",
    "```\n",
    "Qui se base sur l'algorithme *Non-local Means Denoising*\n",
    "\n",
    "**Avec:**\n",
    "- ```h```: la puissance du filtre (une valeur autour de 10 donnera de bons résultats)\n",
    "- ```templateWindowSize``` et ```searchWindowSize``` deux paramètres influençant la taille du filtre. Doivent avoir des valeurs impaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295247027a134135a7bfde955940880b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('barbara.jpg', 'car.png', 'cells.png', 'chest.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def denoising_bw(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], \n",
    "                            var=(0,30,1), h =(7, 13, 1), templateWindowSize=(3,13,2), searchWindowSize=(5,15,2)):\n",
    "    \n",
    "    img = np.array(Image.open('img/' + image).convert(\"L\"))\n",
    "    \n",
    "    noisy = gaussian_noise(img, 0.0, var)\n",
    "    \n",
    "    denoised = cv2.fastNlMeansDenoising(noisy, None, h, templateWindowSize, searchWindowSize) # 10, 9, 13\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, noisy, denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour une image en couleur:\n",
    "\n",
    "**Avec OpenCV:**\n",
    "```Python\n",
    "imgDenoised = cv2.fastNlMeansDenoisingColored(image, None, h, hColor, templateWindowSize, searchWindowSize)\n",
    "```\n",
    "\n",
    "Le seul paramètre qui change est hColor, auquel on donne typiquement la même valeur que h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8a78ca239d4e9a899a8bec6353c6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('barbara.jpg', 'car.png', 'cells.png', 'chest.jpg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def denoising_color(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], \n",
    "                            var=(0,30,1), h =(7, 13, 1), templateWindowSize=(3,13,2), searchWindowSize=(5,15,2)):\n",
    "    \n",
    "    img = np.array(Image.open('img/' + image))\n",
    "    \n",
    "    noisy = gaussian_noise(img, 0.0, var)\n",
    "    \n",
    "    denoised = cv2.fastNlMeansDenoisingColored(noisy, None, h, h, templateWindowSize, searchWindowSize)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, noisy, denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: débruiter une image consister à déterminer la \"valeur optimale\" pour les pixels bruités, afin que l'image retrouve son aspect d'origine (qui n'est pas connu de l'algorithme). Pour ce faire, l'algorithme va tenter de déterminer quels pixels sont bruités, et de modifier leur valeurs pour qu'ils soient plus \"congruents\" avec leurs voisins.\n",
    "\n",
    "Cette opération est similaire à une opération de filtrage (cf. <a href=\"#3\">partie 3</a> du TP), qui sont très souvent utilisés pour débruiter une image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"2\">II. Operations morphologiques</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les **opérations morphologiques** sont un ensemble **d'opérations locales non-linéaires** modifiant la forme (ou morphologie) du contenu d'une image. Ces opérations permettent d'altérer (faire ressortir ou effacer) certaines caractéristiques des images, comme les bordures ou les coins. La **morphologie mathématique** fait référence à une collection de méthodes de traitement d'image pour analyser et modifier des formes spatiales simples, généralement sur des images en noir et blanc.\n",
    "\n",
    "Ces opérations se basent uniquement sur la **position relative des pixels** (comment ils sont agencés spatialement les uns par rapport aux autres), et n'est pas affecté par leurs valeurs, ce qui les rends propices au **traitement d'images binaires**.\n",
    "\n",
    "Chaque opération morphologique petite matrice binaire (généralement imapire et de taille 3x3), appelée **élément structurant** (ES), qui **encode une caractéristique structurelle / motif 2D / prototype de forme géométrique recherché dans l'image**. Les ES spécifient donc des conditions sur l'agencement spatial des pixels que l'on cherche à matcher avec l'image, soit pour trouver une correspondance (*hit*) ou un absence de correspondance (*miss*). \n",
    "\n",
    "Cet ES sera déplacé sur l'ensemble de l'image (*sliding window*) et combiné / matché à chaque pixel selon un certain opérateur : intersection, union, inclusion, complément. Les ES sont égalements appelés **noyaux** (*kernels*), ou encores des **masques**.\n",
    "\n",
    "Cette combinaison consiste à vérifier que le voisinnage du pixel évalué \"correspond\" à l'élément structurant (inclusion, intersection, ...). Le résultat de cette combinaison changera la valeur du pixel original (1 [soit 255] si le test à été un succès (*hit*), 0 sinon (*miss*)), créant ainsi une nouvelle image binaire.\n",
    "\n",
    "<img src=\"https://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/morph-probing.gif\"> | <img src=\"img/Illustrations/erosion.gif\" width=\"400\">\n",
    ":--:|:--: \n",
    " \n",
    "\n",
    "Exemples d'éléments structurants:  \n",
    "\n",
    "<img src=\"img/es/T.png\" width=\"200\"> | <img src=\"img/es/Y.png\" width=\"200\">\n",
    ":--:|:--: \n",
    "\n",
    "***\n",
    "Les opérations morphologiques peuvent être utilisées pour :\n",
    "* Débruiter une image\n",
    "* Améliorer le contraste d'une image\n",
    "* Extraction de caractéristiques: bordures, squelette\n",
    "* Modification de caractéristiques: affinnement / épaississement des bordures, ...\n",
    "* Matching (detection) de caractéristiques\n",
    "\n",
    "Il existe de nombreuses opérations morphologiques : *Erosion, Dilation, Opening, Closing, Thinning, Thickening, Top-Hat, Black-Hat, Hit & Miss, Skeletonization, ...*\n",
    "\n",
    "\n",
    "***\n",
    "Le type d'opération morphologique est conditionné par:\n",
    "* Le type d'opérateur employé pour combiner l'image et l'ES (intersection, union, inclusion, complément).\n",
    "* Le type d'ES utilisé.\n",
    "* Comment ces différents opérateurs et ES sont enchaînés (quand plusieurs sont employés successivement).\n",
    "\n",
    "La plupart de ces opérations sont une combinaison de deux opérations de base: érosion et dilatation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.1 Erosion & Dilatation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.a Erosion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L'érosion** (*Erode / Shrink / Reduce*) est une des opérations morphologiques de base, qui **érode les bordures** des objets / régions saillantes (*foreground regions*), i.e. là où les pixels sont blancs (valent 1).\n",
    "\n",
    "Cas d'utilisation de l'érosion :\n",
    "* Eliminer du bruit blanc (*Salt*) du fond (*background* - noir) de l'image.\n",
    "* Affiner / amaincir les formes d'intérêt (*foreground* - blanc).\n",
    "\n",
    "Mathématiquement, l'érosion est formalisée comme : $I' = I \\ominus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/erodbin.gif\">\n",
    "\n",
    "L'érosion recherche une correspondance parfaite entre la région d'image analysée et l'ES : un pixel ne gardera sa valeur de 1 que si ses voisins incluent l'ES (donc valent 1 si le pixel de l'ES qui leur correspond vaut 1 aussi). Vu que les pixels au bord des objets ne vont généralement pas correspondre à l'élément structurant (ayant du noir à proximité), cette opération aura tendance à les faire disparaitre, et donc à ronger les bordures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec OpenCV:\n",
    "\n",
    "```Python\n",
    "morphed = cv2.erode(img, element_structurant, nombre_de_passages)\n",
    "```\n",
    "L'élément structurant doit être une matrice, ou une image chargée en tant que matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1432177117d8448d9f714092230fad58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '10_text.png', '1_j.png', '2_shapes.jp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def erode(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.erode(img, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.b Dilatation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La dilatation** (*Dilation / Grow / Expand*) est la seconde opération morphologique de base, qui **étends les bordures** des objets / régions saillantes (*foreground regions*), i.e. là où les pixels sont blancs (valent 1). \n",
    "\n",
    "Cas d'utilisation de la dilatation :\n",
    "* Eliminer du bruit noir (*Pepper*) des objets d'intérêt (*foreground*) de l'image.\n",
    "* Elargir / renforcer les formes d'intérêt.\n",
    "\n",
    "Mathématiquement, la dilatation est formalisée comme : $I' = I \\oplus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/diltbin.gif\">\n",
    "\n",
    "Lors d'une dilatation, un pixel ne gardera sa valeur de 0 que si ses voisins excluent l'ES (donc valent 0 si le pixel de l'ES qui leur correspond vaut 1). Vu que les pixels au bord des objets ne vont généralement pas correspondre à l'élément structurant (a cause du blanc de l'objet à proximité), cette opération aura tendance à rajouter des pixels blancs autour des bordures, et donc à les épaissir.\n",
    "\n",
    "<u>Remarque</u>: La dilatation est la réciproque de l'érosion: éroder les pixels blancs avec un ES donné revient à dilater les pixels noirs (i.e. *background*) avec le même ES. Si l'on inverse une image N&B, l'érosion aura alors l'effet d'une dilatation, et vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.dilate(img, element_structurant, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce373a7077f4083a3a99eda7729391d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('cells.png', 'j.png', 'shapes.jpg', 'voronoi.png'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def dilate(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.dilate(img, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Ajouter du bruit S&P (via un slider interactif) à l'image sélectionnée, et observer les effets de l'érosion / dilatation dessus.**\n",
    "    \n",
    "    \n",
    "2. **Implémentez le <u>gradient morphologique</u> de l'image: différence entre la dilatation et l'érosion d'une image.**\n",
    "    \n",
    "    \n",
    "3. **En employant uniquement une érosion (ou une dilatation), proposez une solution permettant d'extraire les bordures des objets d'une image binaire.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.2 Ouverture et Fermeture</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.a Ouverture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une ouverture** (*Opening*) est l'enchaînement d'une érosion et d'une dilatation : $I' = opening(I) = dilation(erosion(I))$\n",
    "\n",
    "Mathématiquement, l'ouverture est formalisée comme : $I' = I \\circ B = (I\\ominus B)\\oplus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/opening.png\">\n",
    "<img src=\"http://what-when-how.com/wp-content/uploads/2012/07/tmp26dc191_thumb2.png\">\n",
    "\n",
    "C'est une opération très utilisée en restoration d'image pour traiter le bruit *Salt* dans l'arrière-plan : en effet, l'erosion  va permettre d'éliminer le bruit de fond non voulu, mais va également ronger les bords des objets eux-mêmes. La dilatation successive va donc permettre de restaurer les bords à (presque) leur valeur d'origine, mais sans restaurer le bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963c20f345cc47549226507c40327ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('1_j.png', '2_shapes.jpg', '3_diag_lines.jpg', '4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def closing(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.b Fermeture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Une fermeture** (*Closing*) est l'enchaînement d'une dilatation et d'une érosion : $I' = closing(I) = erosion(dilation(I))$\n",
    "\n",
    "\n",
    "Mathématiquement, la fermeture est formalisée comme : $I' = I \\bullet B = (I\\oplus B)\\ominus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/closing.png\">\n",
    "<img src=\"http://what-when-how.com/wp-content/uploads/2012/07/tmp26dc188_thumb2.png\">\n",
    "\n",
    "C'est une opération très utilisée en restoration d'image pour traiter le bruit *Pepper* dans les objets : en effet, la dilatation va permettre de remplir les \"trous\" non voulus dans un objet (*pepper noise*), mais va également étendre les bords des objets eux-mêmes. L'érosion successive va donc permettre de restaurer les bords à (presque) leur valeur d'origine, mais sans restaurer le bruit.\n",
    "\n",
    "<u>Remarque</u>: La fermeture est la réciproque de l'ouverture: ouvrir les pixels blancs avec un ES donné revient à fermer les pixels noirs avec le même ES. Si l'on inverse une image N&B, l'ouverture aura alors l'effet d'une fermeture, et vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fad23595c364d66b7e089ad2961cca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '1_j.png', '2_shapes.jpg', '3_diag_lin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def closing(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du kernel sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Créez une méthode interactive qui permet:**\n",
    "    * D'ajouter du bruit *Salt*, *Pepper* ou *Salt&Pepper*\n",
    "    * D'afficher dans une grille 3x2 : ([Image d'origine, Image bruitée], [Erodée, Dilatée], [Ouverte, Fermée])\n",
    "    \n",
    "Essayez votre fonction sur les différentes images de démonstration et observez les différences d'effets de chaque opération.\n",
    "\n",
    "2. **Implémentez une chaine de traitement qui va :**\n",
    "    1. Ajouter du bruit S&P à une image\n",
    "    2. Le nettoyer\n",
    "    3. Extraire les bordures des objets de cette image\n",
    "    4. (Si nécessaire) Nettoyer les portions/pixels non-utiles de l'image *edge* extraites\n",
    "\n",
    "\n",
    "3. **Implémentez les deux opérations suivantes et observez:**\n",
    "    1. **Top-Hat**: image - ouverture(image). \n",
    "        Cette opération isole les zones plus petites et de forme similaire à l'élément structurant et plus claires que leur entourage.\n",
    "    2. **Black-Hat**: fermeture(image) - image. \n",
    "        Cette opération isole les zones plus petites et de forme similaire à l'élément l'élément structurant et plus sombres que leur entourage.\n",
    "\n",
    "> <u>Astuce</u>: vous pouvez utiliser les méthodes spécifiques d'OpenCV pour comparer vos résultats :\n",
    "```Python\n",
    "morph = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, es)\n",
    "morph = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, es)\n",
    "```\n",
    "    \n",
    "4. **En partant de l'image N&B des cellules (`9_cells.png`), essayez d'en extraire les contours les plus propres possibles (en utilisant des opérations morphologiques, pre ou post extraction de contours). Réappliquez les contours obtenus à l'image d'origine de sorte à les faire ressortir (amplifier leur luminosité).**\n",
    "    \n",
    "> <u>Astuce</u>: vous pouvez (par exemple) utiliser une opération morphologique *-Hat pour isoler les cellules du background après nettoyage, en en extraire le contour ensuite.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.3 Hit-or-Miss</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The **Hit-or-miss transform** is an operation that detects a given configuration (or pattern) in a binary image, using the morphological erosion operator and a pair of disjoint structuring elements. The result of the hit-or-miss transform is the set of positions where the first structuring element fits in the foreground of the input image, and the second structuring element misses it completely.*\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/hamcrn.gif\">\n",
    "\n",
    "*Here, we use two structuring elements (say B1 and B2). We ask a simple question : does B1 fits the object while, simultaneously, B2 misses the object (i.e. fits the background) ? In other words, we are interested only in those pixels whose neighborhood exactly matches B1 while not matching B2 at the same time.*\n",
    "\n",
    "Mathématiquement, la transformée Hit-or-Miss est formalisée comme : $I' = I\\odot B=(I\\ominus B_1)\\cap (I^c\\ominus B_2)$\n",
    "\n",
    "Avec :\n",
    "* $B_1$ et $B_2$ sont éléments structurants **disjoints**, dont la combinaison donne $B$.\n",
    "* $I^c$ le complément de $I$ : ($I^c = 1 - I$)\n",
    "\n",
    "<img src=\"https://i1.wp.com/theailearner.com/wp-content/uploads/2019/07/hitmiss.png?w=759&ssl=1\">\n",
    "\n",
    "Contrairement aux opérations morphologiques précédentes, les *kernels* des H|M n'est plus binaire, mais trinaire:\n",
    "* 1 (blanc): il faut qu'il y ait 1 dans ce pixel\n",
    "* 0 (gris): on s'en fiche de ce qu'il y à dans ce pixel\n",
    "* -1 (noir): il faut qu'il y ait 0 dans ce pixel\n",
    "\n",
    "L'application de l'ES illustré donnerait :\n",
    "\n",
    "<img src=\"https://i2.wp.com/theailearner.com/wp-content/uploads/2019/07/hitormiss-1.png?w=748&ssl=1\">\n",
    "\n",
    "La transformation hit-or-miss est utilisée pour détecter des patterns spécifiques (celui de l'ES) dans une image.\n",
    "\n",
    "*The hit-or-miss transform has many applications in more complex morphological operations: it is being used to construct the thinning, thickening and convex hull operators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_HITMISS, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b424e77f37bd4b69beb9b24891385846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '10_text.png', '11_text.jpg', '1_j.png…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "resize_slider = widgets.FloatSlider(min=0.2, max=5.0, step=0.2, value=1)\n",
    "\n",
    "@interact\n",
    "def hit_and_miss(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, size=resize_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.array([[-1,-1,-1],[1,1,1],[0,0,0]], dtype=\"int\")\n",
    "    es = cv2.resize(es, None, fx=size, fy=size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_HITMISS, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Générez de nouveaux ES comprenant des zones *hit* et/ou *miss*:**\n",
    "    1. Créez différents types d'éléments structurants (via numpy, ou via `cv2getStructuringElement()`) \n",
    "    2. Les sauvegarder sous forme d'images binaires dans le dossier `img/es` de votre TP pour pouvoir les réutiliser.\n",
    "    3. Les appliquer aux différentes images du TP et observez.\n",
    "    \n",
    "> <u>Astuce</u>:\n",
    "```Python\n",
    "cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "```\n",
    "    \n",
    "Vous pouvez également vous servir de `cv2.resize(es, None, fx=rate, fy=rate, interpolation=cv2.INTER_NEAREST)` pour redimensionner des ES existants.\n",
    "    \n",
    "Vous pouvez vous servir des méthodes suivantes pour convertir un ES entre format image (0-255) et binaire (0-1):\n",
    "```Python\n",
    "def i2b(f):\n",
    "    return np.where(f==0, 1, 0)\n",
    "\n",
    "def b2i(f):\n",
    "    return np.where(f==1, 0, 255)\n",
    "```\n",
    "\n",
    "2. **Trouvez l'ES permettant d'extraire les coins (intersections) des traits horizontaux et verticaux de l'image `4_vert_hor_lines.jpg`. Faites de même avec les diagonales.**\n",
    "    \n",
    "> <u>Astuce</u>: si votre ES ne détecte rien, essayez de le `resize`\n",
    "    \n",
    "    \n",
    "3. **[<u>Bonus</u>] A partir des intersections extraites de l'image `4`, récoltez les coordonnées (x,y) des pixels blancs, regroupez-les en blobs, et tracez des lignes entre le centre de ces blobs de sorte à essayer de re-créer l'image d'origine.**\n",
    "\n",
    "<u>Astuces</u>:\n",
    "\n",
    "```Python\n",
    "indices = np.where(img == [1])\n",
    "coordinates =  numpy.asarray(zip(indices[0], indices[1]))\n",
    "\n",
    "detector = cv2.SimpleBlobDetector()\n",
    "keypoints = detector.detect(img)\n",
    " \n",
    "# Pour visualiser les zones détectées\n",
    "res = cv2.drawKeypoints(img, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# Pour dessiner une ligne\n",
    "cv2.line(img, pt1, pt2, color)\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n",
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "thick_slider = widgets.IntSlider(min=1, max=20, step=1, value=1)\n",
    "scale_slider = widgets.IntSlider(min=1, max=100, step=1, value=1)\n",
    "resize_slider = widgets.FloatSlider(min=0.0, max=5.0, step=0.5, value=1.0)\n",
    "\n",
    "@interact_manual\n",
    "def extract_letter(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], \n",
    "          invert=False, n_passages=pass_slider, thick=thick_slider, scale=scale_slider, resize=resize_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    '''\n",
    "    size = (800,800)\n",
    "    es = np.zeros(size, dtype='uint8')\n",
    "    es = cv2.putText(es, \"M\", org=(int(0.3*size[0]), int(0.9*size[1])), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=scale, color=(255), thickness=thick, lineType=cv2.LINE_AA)\n",
    "    es = cv2.resize(es, None, fx=resize, fy=resize, interpolation=cv2.INTER_NEAREST)\n",
    "    es = np.array(1.0 * (np.array(es) > 127), dtype=\"uint8\")\n",
    "    '''\n",
    "    es = Image.open('img/morpho/0_M.jpg').convert(\"L\")\n",
    "    es = np.array(1.0 * (np.array(es) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    #morphed = cv2.morphologyEx(img, cv2.MORPH_HITMISS, es, iterations=n_passages)\n",
    "    morphed = cv2.dilate(cv2.erode(img, es, iterations=n_passages), es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.4 Thinning & Thickening</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import skimage.morphology as skimorph\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()\n",
    "    \n",
    "def affichage_1x2(img1,img2):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    plt.subplot(122), plt.imshow(img2, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.a Thinning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Thinning__ is used to thin the foreground region such that its extent and connectivity are preserved, producing a **topologically equivalent** image. Preserving extent means preserving the endpoints of a structure, whereas preserving connectivity can refer to either 4-connected or 8-connected.*\n",
    "\n",
    "*Pixel connectivity illustration:*\n",
    "\n",
    "<img src=\"https://images.deepai.org/converted-papers/1906.03366/images/Connectedness.jpg\" width=300>\n",
    "\n",
    "*Thinning is mostly used for producing skeletons (which serve as image descriptors), and for reducing the output of the edge detectors to a one-pixel thickness.*\n",
    "\n",
    "<img src=\"https://i0.wp.com/theailearner.com/wp-content/uploads/2019/07/thinresult.png?resize=1024%2C141\">\n",
    "\n",
    "Thinning can be formalized based on the Hit-or-Miss transform : $I\\otimes B = I - (I\\odot B)$\n",
    "\n",
    "*The choice of structuring element determines under what situations a foreground pixel will be set to background, and hence it determines the application for the thinning operation. The binary structuring elements used for thinning are of the extended type described under the hit-and-miss transform (i.e. they can contain both ones and zeros).*\n",
    "\n",
    "*The operator is normally applied repeatedly until it causes no further changes to the image (i.e. until convergence). Alternatively, in some applications, e.g. pruning, the operations may only be applied for a limited number of iterations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29071ef32c9349a08e32392cbbb3b620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '1_j.png', '2_shapes.jpg', '3_diag_lin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def thinning(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.thin(img)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple en combinant érosions et dilatations (via OpenCV) sur une image générée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd7a22a41f4359910586ae99d35c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='thick', max=20, min=2, step=2), Output()), _dom_classes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_text_image(size, text, thick=5):\n",
    "    img = np.zeros(size, dtype='uint8')\n",
    "    cv2.putText(img, text, org=(int(0.3*size[0]), int(0.3*size[1])), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=3, color=(255), thickness=thick, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "@interact\n",
    "def thinning2(thick=(2,20,2)):\n",
    "    \n",
    "    # Créons une image de démo\n",
    "    img = create_text_image((200,400), \"IBIOM\", thick)\n",
    "    img1 = img.copy()\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    #img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    \n",
    "    # Create an empty output image to hold values\n",
    "    morphed = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    # On morph\n",
    "    # Loop until erosion leads to an empty set\n",
    "    while (cv2.countNonZero(img1)!=0):\n",
    "        # Erosion\n",
    "        erode = cv2.erode(img1, es)\n",
    "        # Opening on eroded image\n",
    "        opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, es)\n",
    "        # Subtract these two\n",
    "        subset = erode - opening\n",
    "        # Union of all previous sets\n",
    "        morphed = cv2.bitwise_or(subset, morphed)\n",
    "        # Set the eroded image for next iteration\n",
    "        img1 = erode.copy()\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.b Thickening:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Thickening__ is a morphological operation that is used to grow selected regions of foreground pixels in binary images, somewhat like dilation or closing. It has several applications such as determining the approximate convex hull of a shape.*\n",
    "\n",
    "*The thickened image consists of the original image plus any additional foreground pixels switched on by the hit-and-miss transform.*\n",
    "\n",
    "*Thickening is the dual of thinning, i.e. thickening the foreground is equivalent to thinning the background.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    "\n",
    "1. **Appliquez la méthode de Thinning d'OpenCV aux différentes images du TP (`img/morpho/`) et observez.**\n",
    "    \n",
    "    \n",
    "2. **Reprenez votre programme du `II.2` et améliorez l'extraction de contours grace au Thinning**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.5 Skeletonization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Skeletonization__ (or Medial axis transform) is a process for reducing foreground regions in a binary image to a skeletal remnant that largely preserves the extent and connectivity of the original region while throwing away most of the original foreground pixels.*\n",
    "\n",
    "<img src=\"http://zone.ni.com/images/reference/en-XX/help/372916T-01/binary_lskeleton01.gif\">\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_morphology_008.png\">\n",
    "\n",
    "*The skeleton can be produced in two main ways :*\n",
    "* _The first is to use some kind of **morphological thinning** that successively erodes away pixels from the boundary (while preserving the end points of line segments) until no more thinning is possible, at which point what is left approximates the skeleton._ \n",
    "* _The alternative method is to first calculate the **distance transform** of the image. The skeleton then lies along the singularities (i.e. creases or curvature discontinuities) in the distance transform._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import skimage.morphology as skimorph\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()\n",
    "    \n",
    "def affichage_1x2(img1,img2):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    plt.subplot(122), plt.imshow(img2, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3388c77ce94838957ae93de1ab4c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '1_j.png', '2_shapes.jpg', '3_diag_lin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def skeletonize(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.skeletonize(img == 1)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez les effets sur l'image de cellules, et sur leur inverse !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.6 Convex Hull</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The **convex hull** is the set of pixels included in the smallest convex polygon that surround all white pixels in the input image.*\n",
    "\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_morphology_009.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cd5b1265e646f9a171bdc9c41750d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('0_M.jpg', '1_j.png', '2_shapes.jpg', '3_diag_lin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def convex_hull(image=[f for f in os.listdir(\"img/morpho/\") if os.path.isfile(os.path.join(\"img/morpho/\", f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open('img/morpho/' + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.convex_hull_image(img == 1)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    "\n",
    "1. **Comparez les effets de la skeletonization et du thinning sur les images du TP.**\n",
    "    \n",
    "    \n",
    "2. **Servez-vous de la transformée Convex Hull pour isoler les cellules en blobs distincts (après les nettoyages appropriés) et comptez le notre de cellules / blobs sur l'image.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "***\n",
    "# Fin du TP3\n",
    "***\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
