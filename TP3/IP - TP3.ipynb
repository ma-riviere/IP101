{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opejyiC7dX1o"
   },
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "<div style=\"text-align:center\"> \n",
    "\n",
    "***\n",
    "# <u>TP3:</u>\n",
    "# Bruit et Opérations morhpologiques\n",
    "    \n",
    "<p style=\"text-align: center; color:gray\"><i>@Author:</i> Marc-Aurèle Rivière</p>\n",
    "\n",
    "***\n",
    "        \n",
    "</div>\n",
    "    \n",
    "<u>**Plan:**</u>\n",
    "\n",
    "1. [**Bruit et Débruitage**](#1)\n",
    "2. [**Opérations morphologiques**](#2): \n",
    "    1. Erosions & Dilatations\n",
    "    2. Ouverture & Fermetures\n",
    "    3. Hit-or-Miss\n",
    "    4. Thinning & Thickening\n",
    "    5. Skeletonization\n",
    "    6. Convex Hull\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79465,
     "status": "ok",
     "timestamp": 1580822579775,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "DSx7yVwidX1t",
    "outputId": "478e9655-b115-4855-de1c-3a56378aa0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on Colaboratory\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''\n",
    "#################################\n",
    "#  Code global pour tout le TP  #\n",
    "#################################\n",
    "'''''''''''''''''''''''''''''''''\n",
    "\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running on Colaboratory\")\n",
    "    from google.colab import drive, files\n",
    "\n",
    "    drive.mount('/content/gdrive', force_remount=True)\n",
    "    root_path = 'gdrive/My Drive/3. Doctorat/Enseignements/[Intro] Image Processing/TP3/'  # A modifier à votre chemin d'accès\n",
    "    img_path = root_path + \"img/\"\n",
    "    morpho_path = img_path + \"morpho/\"\n",
    "else:\n",
    "    print(\"Not running on Colaboratory\")\n",
    "    root_path = \"/\"\n",
    "    img_path = \"img/\"\n",
    "    morpho_path = img_path + \"morpho/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7imxQfk6dX11"
   },
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"1\">I. Bruit et Débruitage</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrhSDh7KdX12"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.1 Bruit</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HR2rwzWTdX13"
   },
   "source": [
    "En traitement du signal (et donc par extension, des images), le **bruit** fait référence à des variations aléatoires \"non-expliquées\" du signal (et donc de la luminance ou couleur des pixels dans notre cas). Ce bruit est donc une dégradation de l'image par rapport à un état d'origine, ou un état optimal espéré.\n",
    "\n",
    "**Ajouter du bruit** à une image revient donc à modifier la valeur de luminance (ou chrominance) de certains pixels par des valeurs \"aléatoires\". En réalité, le bruit observé dans les systèmes électroniques n'est pas aléatoire, mais dépends de processus génératifs qui ne sont pas connus / compris, et est donc considéré / modélisé comme aléatoire. Ce bruit peut  provenir de plusieurs sources: mauvais capteurs, trop faible luminosité lors de la prise de l'image, problèmes d'électronique, dégradation du support de stockage de l'image avec le temps, ...\n",
    "  \n",
    "On distingue deux grandes catégories de bruits:\n",
    "\n",
    "### I.1.a Bruits additifs :\n",
    "\n",
    "Le niveau de bruit est indépendant de la valeur du signal: chaque pixel est uniformément susceptibles d'être bruité. Il n'y à donc pas d'intéraction entre le bruit et le signal.\n",
    "\n",
    "$I'(x,y) = I(x,y) + \\eta(x,y)$\n",
    "\n",
    "<u>Exemples de bruits additifs</u>: Gaussian, ...\n",
    "\n",
    "Les **filtres linéaires** sont efficaces pour retirer les bruits additifis.\n",
    "\n",
    "### I.1.b Bruits multiplicatifs :\n",
    "\n",
    "Le niveau de bruit dépends / est corrélé à la valeur du signal: certains pixels seront plus susceptibles d'être bruités selon leur valeur. On peut parler d'interaction entre le bruit et le signal.\n",
    "\n",
    "<u>Exemples de bruits multiplicatifs</u>: Salt, Pepper, Salt&Pepper, Speckle, Poisson, ...\n",
    "\n",
    "Le **filtre médian** et les **opération morphologiques** sont efficaces pour retirer les bruits multiplicatifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oYqPFTFDdX14"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Fonction d'affichage utilisant OpenCV pour calculer l'histogramme de l'image\n",
    "def affichage_2x2(img1, img2, c=\"gray\"):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, c)\n",
    "    ax1.set_title(\"Image originale\", color='b')\n",
    "    ax2 = plt.subplot(222)\n",
    "    ax2.hist(img1.ravel(), 256, [0,256])\n",
    "    ax2.set_title(\"Histogramme de l'image originale\", color='b')\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, c)\n",
    "    ax3.set_title(\"Image bruitée\", color='c')\n",
    "    ax4 = plt.subplot(224, sharex=ax2, sharey=ax2)\n",
    "    ax4.hist(img2.ravel(), 256, [0,256])\n",
    "    ax4.set_title(\"Histogramme de l'image bruitée\", color='c')\n",
    "    plt.show()\n",
    "\n",
    "# Affichons l'image originale, modifiée, et leurs histogrames (*smoothed* via un KDE - Kernel Density Estimation)\n",
    "def affichage_2x2_smoothed(img1, img2):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, \"gray\")\n",
    "    ax1.set_title(\"Image originale\")\n",
    "    ax2 = plt.subplot(222)\n",
    "    sns.kdeplot(np.array(img1).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,256], cut=0)\n",
    "    ax2.set_title(\"Histogramme (KDE) de l'original\")\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, \"gray\")\n",
    "    ax3.set_title(\"Image bruitée\")\n",
    "    ax4 = plt.subplot(224, sharex=ax2, sharey=ax2)\n",
    "    sns.kdeplot(np.array(img2).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,256], cut=0)\n",
    "    ax4.set_title(\"Histogramme (KDE) de l'image bruitée\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beNlVWkBdX18"
   },
   "source": [
    "### I.1.a Bruit Gaussien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVQoj7VgdX19"
   },
   "source": [
    "Un **bruit gaussien** est un **bruit additif** distribué selon une **loi Normale**, ajouté à l'ensemble de l'image. Cela signifie que chaque pixel de l'image va se voir ajouter une valeur piochée aléatoirement dans une distribution Gaussienne :\n",
    "    \n",
    "$X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2})$\n",
    "\n",
    "L'intensité du bruit est lié à la variance $\\sigma^2$ de la distribution utilisée pour modéliser ce bruit. Plus $\\sigma^2$ augmente, plus l'histogramme de l'image bruité se rapprochera d'une loi Normale, le bruit dominant progressivement le signal.\n",
    "\n",
    "La nouvelle intensité de chaque pixel s'exprime par :\n",
    "\n",
    "$I'(x,y) = I(x,y) + \\mathcal{N}(\\mu,\\,\\sigma^{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813,
     "referenced_widgets": [
      "20db1f7840074966ae90fc4ed045f573",
      "4c85e57a8c73446fae8045a493bf7c5a",
      "f1d8c776260f4b20b687afcd7397a176",
      "7f24e48beb7242ea8ea9febf1d4e8cee",
      "9e733f5724674678bd44b7d9fcdfc907",
      "7d8e06e94a754edc89d33e166e4dbd72",
      "191e9d9772ef4a9ab40035638a8393ee",
      "dcca8db3e42b401389a7fd50ca29e678",
      "40b6fe5f6c7549568c529510815804fa",
      "bed145ad59744143a75d429783a47d65",
      "e9faedb4ea50476e89f805593cb14812",
      "20008a08fd7c47768591cfc8e658da4c"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5479,
     "status": "ok",
     "timestamp": 1580822626305,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "Sknp_X6udX1-",
    "outputId": "119339a0-eab6-4f4a-8575-6ca6208543bf"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def gaussian_noise(image=[f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))], mean=(-2,2,0.5), var=(0,30,1)):\n",
    "    img = np.array(Image.open(img_path + image).convert(\"L\"))\n",
    "    \n",
    "    # Ajoutons un bruit Gaussien (normal) de moyenne $mean$ et variance $var$\n",
    "    noisy = img + np.random.normal(mean, var, img.shape)\n",
    "    noisy = np.clip(noisy, 0, 255) \n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CI14TFBdX2D"
   },
   "source": [
    "### I.1.b Bruit Salt-and-Pepper (S&P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ftnom--udX2F"
   },
   "source": [
    "Un **bruit de Poisson** (ou *Impulse noise*, ou *Spike noise*) est un **bruit multiplicatif** qui va affecter un certain % de l'image. Cela signifie que chaque pixel de l'image va avoir une certaine chance de passer à 0 (Pepper) ou 255 (Salt), les pixels noirs ayant une plus grande chance de devenir blancs, et vice-versa.\n",
    "\n",
    "*Salt corresponds to pixels in a dark region that somehow passed the threshold for bright, and pepper corresponds to pixels in a bright region that were below threshold. Salt and pepper might be classification errors resulting from variation in the surface material or illumination, or perhaps noise in the analog/digital conversion process in the frame grabber.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780,
     "referenced_widgets": [
      "181764ae94c44fc5bc67bed234e61ee3",
      "ba0df8eeaf3f4db1a396cd65c3e2da6f",
      "532f4a555db24898b1fbbdc673721f5f",
      "c3d4f5c500574218844a83f50db9c826",
      "d8c5a361fcd34d218c022291f0d35425",
      "fcf3e4f915b14de78ebf51a6e2fc87a5",
      "7b3b7572e31a419cb7c2bade9c0cf734",
      "9d926f2deb1049a783a2431787c6ba1c",
      "34c2eed5778f4d5a898ced2e927eb239"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3510,
     "status": "ok",
     "timestamp": 1580822717183,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "5AT_sjHodX2G",
    "outputId": "8b284586-7919-4a82-ecef-f3ab3f5c5003",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def sp_noise(image=[f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))], sp_amount=(0,1,0.05)):\n",
    "    img = np.array(Image.open(img_path + image).convert(\"L\"))\n",
    "    \n",
    "    # Ajoutons un bruit Gaussien (normal) de moyenne $mean$ et variance $var$\n",
    "    noisy_sp = random_noise(img, mode='s&p', amount=sp_amount)\n",
    "    # The above function returns a floating-point image on the range [0, 1], thus we changed it to 'uint8'\n",
    "    noisy_sp = np.array(255 * noisy_sp, dtype='uint8')\n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLmS0LZldX2L"
   },
   "source": [
    "### I.1.c Poisson noise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiHMIeFXdX2M"
   },
   "source": [
    "Un **bruit de Poisson** (ou *Shot noise*) est un **bruit multiplicatif** modélisé par une **loi de Poisson**, appliqué à toute l'image. Cela signifie que chaque pixel de l'image va voir sa valeur recalculée selon la loi de Poisson, de moyenne et variance égales à $\\lambda$:\n",
    "\n",
    "$X \\sim \\mathcal P(\\lambda)$, avec $P\\left( x \\right) = \\dfrac{{e^{ - \\lambda } \\lambda ^x }}{{x!}}$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/440px-Poisson_pmf.svg.png\">\n",
    "\n",
    "<u>Remarque</u>: Plus $\\lambda$ est grand, et plus la distribution de Poisson se rapproche d'une loi Normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780,
     "referenced_widgets": [
      "3b9a8eed4ed7495c83f608f7e45d3768",
      "a1c82c9b6de44ac99b19f09b3005e6df",
      "b698adc0e8d84a578b3bd99fedfa908b",
      "e166aab359ce44cfa74752670ff195e0",
      "2a58b53f7bf74555a4d279ff3555dca7",
      "097771d5b14a4dea88444f2cc4af4087",
      "273d871571b9472ba34ace335e8476d6",
      "01a540f3acaf41d294aed2d651310276",
      "a73dfd828f0740e1a68a273fff1abb9b"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4054,
     "status": "ok",
     "timestamp": 1580822723774,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "IUukHwfedX2N",
    "outputId": "4cdebc24-9da4-451c-faa3-8ba3280725de"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def poisson_noise(image=[f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))], lambda_const=(0,50,5)):\n",
    "    img = np.array(Image.open(img_path + image).convert(\"L\"))\n",
    "    \n",
    "    noisy = np.random.poisson(img / 255.0 * lambda_const) / lambda_const * 255\n",
    "    noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_2x2(img, noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdJ9s8hMdX2R"
   },
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Créez une méthode interactive permettant de choisir l'un des trois types de bruits mentionnés et de l'appliquer à une image couleur.**\n",
    "    \n",
    "    \n",
    "2. **Implémentez deux méthodes permettant de rajouter du bruit *Salt* et *Pepper* séparément.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppslocRYdX2S"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYhmpkyQdX2Y"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.2 Débruitage</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQWegWcbdX2Z"
   },
   "source": [
    "L'objectif général des méthodes de débruitage est de retrouver au mieux l'image d'origine à partir d'une image bruitée, ce qui nécessite (1) de deviner quels pixels sont bruités, et (2) d'estimer la valeur optimale que ces pixels devraient avoir, en fonction de celles des pixels alentours. On parle **d'interpolation** des valeurs.\n",
    "\n",
    "Estimer le type de bruit auquel le signal est soumis (en fonction des sources suspectées de bruit dans le système) va influencer la stratégie de débruitage à appliquer. De manière général, ces stratégies tentent de déterminer quelles variations d'intensité sont du bruit ou des détails réels (signal) de l'image afin de moyenner/filtrer le bruit tout en préservant les détails.\n",
    "\n",
    "Aucun de ces algorithmes n'est parfait, et ils entraînent souvent une perte d'information dans l'image.\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/pagina-personal.appspot.com/img_blog/dual_rof_denoising/gradient_descent_dual_rof.png\" heigth=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjvXDm-_dX2a"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def sp_noise(img, prob=0.05):\n",
    "    noisy_sp = random_noise(img, mode='s&p', amount=prob)\n",
    "    return np.clip(noisy_sp, 0, 255)\n",
    "\n",
    "def gaussian_noise(img, std=10.0):\n",
    "    noisy_gauss = img + np.random.normal(0.0, std, img.shape)\n",
    "    return np.clip(noisy_gauss, 0, 255).astype(np.uint8)\n",
    "\n",
    "def affichage_1x3(img1, img2, img3):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    plt.subplot(131), plt.imshow(img1, cmap='gray'), plt.title(\"Image originale\", color='b')\n",
    "    plt.subplot(132), plt.imshow(img2, cmap='gray'), plt.title(\"Image bruitée\", color='b')\n",
    "    plt.subplot(133), plt.imshow(img3, cmap='gray'), plt.title(\"Image débruitée\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Q4nrXAkdX2d"
   },
   "source": [
    "#### Pour une image en noir et blanc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gt2B879BdX2e"
   },
   "source": [
    "**Avec OpenCV:**\n",
    "```Python\n",
    "imgDenoised = cv2.fastNlMeansDenoising(image, None, h, templateWindowSize, searchWindowSize)\n",
    "```\n",
    "Qui se base sur l'algorithme *Non-local Means Denoising*, efficace pour les bruits Gaussiens.\n",
    "\n",
    "**Avec:**\n",
    "- ```h```: la force du filtre : une valeur élevée supprimera le bruit plus efficacement, mais risque aussi de lisser (et donc faire disparaitre) les détails de l'image.\n",
    "- ```templateWindowSize``` et ```searchWindowSize``` deux paramètres influençant la taille du filtre. Doivent avoir des valeurs impaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519,
     "referenced_widgets": [
      "9137e250697c4d838e8e08041e1f8918",
      "04cf710d469f4a31a060a682b067b508",
      "f2526f63101e4a43bd5995112c2a38c2",
      "5eb8683fd3cb43c1be595d8c2c2f1fed",
      "97932df993a24bd6a38ba50673a45053",
      "bcdad8290760410fa6e483f51f1a9cd0",
      "b31526a9093045e4acc2c0a791189db6",
      "8c450826e3b04dccb5a0d3bebe1444c3",
      "05677fef060443f58b1467c9345c7fc0",
      "7a439f0b96b4446aa150547dd0607d28",
      "02b46c278c1f446abc388cc14a0868f2",
      "876772ea380b4ffc8cf9d44662891903",
      "d407a2db49634102aff97821236543cb",
      "6f6d326bbafc4d0d8707a3fd970359de",
      "8a12cf40e5c941d588e5d03286b56d2d",
      "e628698c818e472c899b9238a445b7e7",
      "202169cb931d4320a7b31bdf6dd5e216",
      "ade36dcdee514443bef1c396bcf33864"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5061,
     "status": "ok",
     "timestamp": 1580822745199,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "dGExaSiddX2f",
    "outputId": "6b5c83c7-74e7-40a8-9eea-5ac200e9579c"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def denoising_bw(image=[f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))], \n",
    "                            var=(0,30,1), h =(7, 13, 1), templateWindowSize=(3,13,2), searchWindowSize=(5,15,2)):\n",
    "    \n",
    "    img = np.array(Image.open(img_path + image).convert(\"L\"))\n",
    "    \n",
    "    noisy = gaussian_noise(img, var)\n",
    "    \n",
    "    denoised = cv2.fastNlMeansDenoising(noisy, None, h, templateWindowSize, searchWindowSize) # 10, 9, 13\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, noisy, denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwJ-y1AIdX2j"
   },
   "source": [
    "#### Pour une image en couleur:\n",
    "\n",
    "```Python\n",
    "imgDenoised = cv2.fastNlMeansDenoisingColored(image, None, h, hColor, templateWindowSize, searchWindowSize)\n",
    "```\n",
    "\n",
    "Le seul paramètre qui change est hColor, auquel on donne typiquement la même valeur que h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519,
     "referenced_widgets": [
      "af88b1998bff404181aeb5771b57ccf8",
      "8fffe0325593409d8344f22264a9bc30",
      "2430943e772a42c9ad872e9b6dd845db",
      "57d053c4589e48d2931ad17c3106f1e2",
      "d283cede1edc4d6d8528afde2090188d",
      "89d1d14ffc904ad3862a6baf3d5117c5",
      "21e255a7c84047059a0685ba29886849",
      "ff6b3e836aca460bbfc5fa51c22b4389",
      "c2203ca5a7864cfa989f1fa74e179409",
      "b76439a61af94b42a03c89ff1a37a40b",
      "25d24501d4f34b79a0845ac33f8d98d5",
      "f3f320ac99634dd4a54e4591f3f4cd15",
      "36bcafea627148a687157fe52abf8c6b",
      "b23c2fa3d0ec4df580484ba8e6d196dc",
      "73c6ce35cb9d451795697bd2d074fe91",
      "d81f42fe0d064c439a3eeb8d15aa63af",
      "19c2ff5d8ee74a8db9d621f11b078a35",
      "f608e6fbaf184c1b8bd3ad013a19301e"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7665,
     "status": "ok",
     "timestamp": 1580822756732,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "G_lEqS0KdX2m",
    "outputId": "72297616-88fe-410f-8c94-117f4f6407c5"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def denoising_color(image=[f for f in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, f))], \n",
    "                            var=(0,30,1), h =(7, 13, 1), templateWindowSize=(3,13,2), searchWindowSize=(5,15,2)):\n",
    "    \n",
    "    img = np.array(Image.open(img_path + image))\n",
    "    \n",
    "    noisy = gaussian_noise(img, var)\n",
    "    \n",
    "    denoised = cv2.fastNlMeansDenoisingColored(noisy, None, h, h, templateWindowSize, searchWindowSize)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, noisy, denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44ghtcjcdX2q"
   },
   "source": [
    "**Remarque**: débruiter une image consister à déterminer la \"valeur optimale\" pour les pixels bruités, afin que l'image retrouve son aspect d'origine (qui n'est pas connu de l'algorithme). Pour ce faire, l'algorithme va tenter de déterminer quels pixels sont bruités, et de modifier leur valeurs pour qu'ils soient plus \"congruents\" avec leurs voisins.\n",
    "\n",
    "Cette opération est similaire à une opération de filtrage (cf. TP4), très souvent utilisés pour débruiter une image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSw_7GgQdX2r"
   },
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"2\">II. Operations morphologiques</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_fRABtydX2t"
   },
   "source": [
    "Les **opérations morphologiques** sont un ensemble **d'opérations locales non-linéaires** modifiant la forme (ou morphologie) du contenu d'une image. Ces opérations permettent d'altérer (faire ressortir ou effacer) certaines caractéristiques des images, comme les bordures ou les coins. La **morphologie mathématique** fait référence à une collection de méthodes de traitement d'image pour analyser et modifier des formes spatiales simples, généralement sur des images en noir et blanc.\n",
    "\n",
    "Ces opérations se basent uniquement sur la **position relative des pixels** (comment ils sont agencés spatialement les uns par rapport aux autres), et n'est pas affecté par leurs valeurs, ce qui les rends propices au **traitement d'images binaires**.\n",
    "\n",
    "Chaque opération morphologique est une petite matrice binaire (généralement impaire et de taille 3x3), appelée **élément structurant** (ES), qui **encode une caractéristique structurelle / motif 2D / prototype de forme géométrique recherché dans l'image**. Les ES spécifient donc des conditions sur l'agencement spatial des pixels que l'on cherche à matcher avec l'image, soit pour trouver une correspondance partielle (*hit*), totale (*fit*), ou un absence de correspondance (*miss*). \n",
    "\n",
    "Cet ES sera déplacé sur l'ensemble de l'image (*sliding window*) et combiné / matché à chaque pixel selon un certain opérateur : intersection, union, inclusion, complément. Les ES sont égalements appelés **noyaux** (*kernels*), ou encores des **masques**.\n",
    "\n",
    "Cette combinaison consiste à vérifier que le voisinnage du pixel évalué \"correspond\" à l'élément structurant (inclusion, intersection, ...). Le résultat de cette combinaison changera la valeur du pixel original (1 [soit 255] si le test à été un succès (*hit*), 0 sinon (*miss*)), créant ainsi une nouvelle image binaire.\n",
    "\n",
    "<img src=\"https://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/morph-probing.gif\"> | <img src=\"https://drive.google.com/uc?id=1BkDWys9n8JNSUpMWM2rCNaLapALjMEep\">\n",
    ":--:|:--:  \n",
    "\n",
    "Exemples d'éléments structurants:  \n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1hJ789nqs0FX0GyvvKh5rOC9u6u8Ze6ED\"> | <img src=\"https://drive.google.com/uc?id=1-HLGgoLoyeZ9km7oHMfEDbbHLgqBPxrp\" width=\"40%\">\n",
    ":--:|:--: \n",
    "\n",
    "***\n",
    "Les opérations morphologiques peuvent être utilisées pour :\n",
    "* Débruiter une image\n",
    "* Améliorer le contraste d'une image\n",
    "* Extraction de caractéristiques: bordures, squelette\n",
    "* Modification de caractéristiques: affinnement / épaississement des bordures, ...\n",
    "* Matching (detection) de caractéristiques\n",
    "\n",
    "Il existe de nombreuses opérations morphologiques : *Erosion, Dilation, Opening, Closing, Thinning, Thickening, Top-Hat, Black-Hat, Hit & Miss, Skeletonization, ...*\n",
    "\n",
    "\n",
    "***\n",
    "Le type d'opération morphologique est conditionné par:\n",
    "* Le type d'opérateur employé pour combiner l'image et l'ES (intersection, union, inclusion, complément).\n",
    "* Le type d'ES utilisé.\n",
    "* Comment ces différents opérateurs et ES sont enchaînés (quand plusieurs sont employés successivement).\n",
    "\n",
    "La plupart de ces opérations sont une combinaison de deux opérations de base: érosion et dilatation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MA_qobrTdX2u"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='binary', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YJqfDHzdX2x"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.1 Erosion & Dilatation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WDTnoRFdX2y"
   },
   "source": [
    "### II.1.a Erosion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vv427Ae0dX2z"
   },
   "source": [
    "**L'érosion** (*Erode / Shrink / Reduce*) est une des opérations morphologiques de base, qui **érode les bordures** des objets / régions saillantes (*foreground regions*), i.e. là où les pixels sont blancs (valent 1).\n",
    "\n",
    "Cas d'utilisation de l'érosion :\n",
    "* Eliminer du bruit blanc (*Salt*) du fond (*background* - noir) de l'image.\n",
    "* Affiner / amaincir les formes d'intérêt (*foreground* - blanc).\n",
    "\n",
    "Mathématiquement, l'érosion est formalisée comme : $I' = I \\ominus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/erodbin.gif\">\n",
    "\n",
    "L'érosion recherche une correspondance parfaite entre la région d'image analysée et l'ES : un pixel ne gardera sa valeur de 1 que si ses voisins incluent l'ES (donc valent 1 si le pixel de l'ES qui leur correspond vaut 1 aussi). Vu que les pixels au bord des objets ne vont généralement pas correspondre à l'élément structurant (ayant du noir à proximité), cette opération aura tendance à les faire disparaitre, et donc à ronger les bordures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-6Dn1AANdX22"
   },
   "source": [
    "##### Avec OpenCV:\n",
    "\n",
    "```Python\n",
    "morphed = cv2.erode(img, element_structurant, nombre_de_passages)\n",
    "```\n",
    "L'élément structurant doit être une matrice, ou une image chargée en tant que matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "8889a57ad7ea49d790c71e8e746f07c1",
      "b8eefb778a22492db07b86579701a225",
      "30f5e5100f7e40a0bda4da2f6bc30644",
      "534f2c56d62a49fbab97427c9e62c0c4",
      "a676123fcece4047a7ebc1814f46a68e",
      "2cb23cbe8b1e4520b9a4b4cc98f6683b",
      "e4eaffc016454453a28495fb0fc323dd",
      "810b5335d91d4612876a6e8a14756714",
      "f53944f0bdd14219a1b1f7fe1a13795c",
      "7eb6a5d33a8542bcbefdbfe6afa5ab35",
      "b9699dcbc49347db939fc4a5eeb03303",
      "88ba1d685d284477ba38bd807f8921e8",
      "748f90dab32e4f05b46c93df92d66c11",
      "adbaa6c876e64524912d5761684a7e04",
      "8a5b2569072d481184fac99daf6dbeaf"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2116,
     "status": "ok",
     "timestamp": 1580823676537,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "Q4ln7OzVdX23",
    "outputId": "e7ebc76b-5041-40a5-fe59-fb52b070fd11"
   },
   "outputs": [],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def erode(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.erode(img, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSsX_xjGdX26"
   },
   "source": [
    "### II.1.b Dilatation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaUT-UzkdX28"
   },
   "source": [
    "**La dilatation** (*Dilation / Grow / Expand*) est la seconde opération morphologique de base, qui **étends les bordures** des objets / régions saillantes (*foreground regions*), i.e. là où les pixels sont blancs (valent 1). \n",
    "\n",
    "Cas d'utilisation de la dilatation :\n",
    "* Eliminer du bruit noir (*Pepper*) des objets d'intérêt (*foreground*) de l'image.\n",
    "* Elargir / renforcer les formes d'intérêt.\n",
    "\n",
    "Mathématiquement, la dilatation est formalisée comme : $I' = I \\oplus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/diltbin.gif\">\n",
    "\n",
    "Lors d'une dilatation, un pixel ne gardera sa valeur de 0 que si ses voisins excluent l'ES (donc valent 0 si le pixel de l'ES qui leur correspond vaut 1). Vu que les pixels au bord des objets ne vont généralement pas correspondre à l'élément structurant (a cause du blanc de l'objet à proximité), cette opération aura tendance à rajouter des pixels blancs autour des bordures, et donc à les épaissir.\n",
    "\n",
    "<u>Remarque</u>: La dilatation est la réciproque de l'érosion: éroder les pixels blancs avec un ES donné revient à dilater les pixels noirs (i.e. *background*) avec le même ES. Si l'on inverse une image N&B, l'érosion aura alors l'effet d'une dilatation, et vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFZdkOvHdX29"
   },
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.dilate(img, element_structurant, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "fa6e630b161b4b52a7e860731bacd920",
      "109e3ba5108e46d99e76770201db67f4",
      "6f26f765c5324260a3d0a38cac5176f3",
      "9f2e138093414b7b9b50b33a9fd1f460",
      "1da2961fb29c446bb1fe4b9c86d74f4b",
      "e4dc1e12043b427f959e0692e8bb0c3e",
      "f01245c886b14caa96a71624f660122a",
      "5ee83b2018564bbb9cd2d33d205868d3",
      "50277a38a53748b8a1063790e59ac5af",
      "cef764bf6b5345fb8a68582f77e2ac74",
      "7261cb7b619d43c8a37e24b91aea6d75",
      "2cfe082aec214761a8b3290c322849aa",
      "3359b7afef4b4e73b77a28ff09dd4c58",
      "a1c37509b3cb4a50bce96456b271ab9c",
      "c253210fc85f48f989bc98d25c3e9598"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3025,
     "status": "ok",
     "timestamp": 1580823777921,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "3Nkdx95DdX2-",
    "outputId": "baf0f0fe-56d1-48f2-f689-a374838579ab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def dilate(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.dilate(img, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXGZQlkXdX3C"
   },
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Ajouter du bruit S&P (via un slider interactif) à l'image sélectionnée, et observer les effets de l'érosion / dilatation dessus.**\n",
    "    \n",
    "    \n",
    "2. **En utilisant une seule opération morphologique (érosion ou dilatation), proposez une solution permettant d'extraire les bordures des objets d'une image binaire.**\n",
    "    \n",
    "    \n",
    "3. **Implémentez le <u>gradient morphologique</u> (différence entre la dilatation et l'érosion d'une image) d'une image de manière interactive.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J481lUsndX3E"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8H_BuSCldX3J"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.2 Ouverture et Fermeture</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xtBnx0vdX3K"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='binary', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U890gg6odX3N"
   },
   "source": [
    "### II.2.a Ouverture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRO-Vvv0dX3O"
   },
   "source": [
    "**Une ouverture** (*Opening*) est l'enchaînement d'une érosion et d'une dilatation : $I' = opening(I) = dilation(erosion(I))$\n",
    "\n",
    "Mathématiquement, l'ouverture est formalisée comme : $I' = I \\circ B = (I\\ominus B)\\oplus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/opening.png\">    \n",
    "    \n",
    "<img src=\"http://what-when-how.com/wp-content/uploads/2012/07/tmp26dc191_thumb2.png\">\n",
    "\n",
    "C'est une opération très utilisée en restoration d'image pour traiter le bruit *Salt* dans l'arrière-plan : en effet, l'erosion  va permettre d'éliminer le bruit de fond non voulu, mais va également ronger les bords des objets eux-mêmes. La dilatation successive va donc permettre de restaurer les bords à (presque) leur valeur d'origine, mais sans restaurer le bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvTnhxzudX3P"
   },
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "bc0a86ef84244cc996dc6b0774f4cf3a",
      "7932f075264b42cb99dfcbb1f2fc2d46",
      "194adabdcfb849c6b1a6b8fe26026b0b",
      "f47a5dd4b10d433781e79ece69f0a44d",
      "e44d7365730e4023aab4cbf3cea1f7ef",
      "05196e15758642a492949a71b18c4747",
      "ecd99b7ef961402eb9fa718904c00f02",
      "363a6a0d4dc640908fe1a7038b2243c1",
      "6fa59a206cc4425ab7b42750056e54d3",
      "a9504c03521e4d0083ed7fe0ae88df74",
      "6d30a2eaa9934620ac7afa299f0606ad",
      "65d6dd04881f42e99c974c3d3e503ae1",
      "109f5dde53f34a11a872a59fa744a4e1",
      "2003337d1b6845cd989f774a6a1d7e21",
      "ff2054dc83a7492dbc088df3cb65184d"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1575,
     "status": "ok",
     "timestamp": 1580823892645,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "JTS6gXbQdX3Q",
    "outputId": "d39a2306-6d58-4736-d1dc-5ecb0d1e0cb4"
   },
   "outputs": [],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def closing(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_OPEN, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du filtre sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQsuLdH2dX3T"
   },
   "source": [
    "### II.2.b Fermeture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzzxEilvdX3U"
   },
   "source": [
    "**Une fermeture** (*Closing*) est l'enchaînement d'une dilatation et d'une érosion : $I' = closing(I) = erosion(dilation(I))$\n",
    "\n",
    "\n",
    "Mathématiquement, la fermeture est formalisée comme : $I' = I \\bullet B = (I\\oplus B)\\ominus B$, avec $B$ l'élément structurant.\n",
    "\n",
    "<img src=\"https://opencv-python-tutroals.readthedocs.io/en/latest/_images/closing.png\">\n",
    "<img src=\"http://what-when-how.com/wp-content/uploads/2012/07/tmp26dc188_thumb2.png\">\n",
    "\n",
    "C'est une opération très utilisée en restoration d'image pour traiter le bruit *Pepper* dans les objets : en effet, la dilatation va permettre de remplir les \"trous\" non voulus dans un objet (*pepper noise*), mais va également étendre les bords des objets eux-mêmes. L'érosion successive va donc permettre de restaurer les bords à (presque) leur valeur d'origine, mais sans restaurer le bruit.\n",
    "\n",
    "<u>Remarque</u>: La fermeture est la réciproque de l'ouverture: ouvrir les pixels blancs avec un ES donné revient à fermer les pixels noirs avec le même ES. Si l'on inverse une image N&B, l'ouverture aura alors l'effet d'une fermeture, et vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhIi2Qj2dX3V"
   },
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535,
     "referenced_widgets": [
      "c21044905ba94db3b06fe0ec73637f82",
      "889801be112a495694f939d008494d03",
      "647d6f732b7e46d28cb8aa6c4076d133",
      "fecce44eb1654c86989702a55b5fdf6e",
      "a42bef5b2ef4425d9b486832d7faea3f",
      "434fa9710bd74bf58715264869e244a7",
      "edf8b43e2f03463f997918e79e08deb3",
      "bbd8cbc40b2d452f8684a1efa9572cdb",
      "7102051dcd8b4c46bee3762258f0a25a",
      "e7c537978f364efebee319f385a39d35",
      "d53ec4c5be5246eca33afa0294008f29",
      "a16f878987704b6bad9b42a5caed6fa4",
      "5b978368d4fd442aa947fa8ab9f92186",
      "1bf4cd30bea842d39f294b2bb954893b",
      "6f0da897e08f43ae9c1c778593a8a5a2"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22390,
     "status": "ok",
     "timestamp": 1580202313986,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "L5uk6_sYdX3Y",
    "outputId": "259ae624-3894-45f2-d79c-72c9ac418745"
   },
   "outputs": [],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "es_size_slider = widgets.IntSlider(min=3, max=15, step=2, value=3)\n",
    "\n",
    "@interact\n",
    "def closing(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], \n",
    "          invert=False, n_passages=pass_slider, taille_es=es_size_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.ones((taille_es,taille_es), dtype=np.int)\n",
    "\n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez l'effet du nombre de passes et de la taille du kernel sur le résultat !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfnFWQvTdX3b"
   },
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Créez une méthode interactive qui permet:**\n",
    "    * D'ajouter du bruit *Salt&Pepper*\n",
    "    * D'afficher l'image bruitée suivie d'une grille 2x2 : ([Erodée], [Dilatée]), ([Ouverte], [Fermée])\n",
    "    \n",
    "> Essayez votre fonction sur les différentes images de démonstration et observez les différences d'effets de chaque opération.\n",
    "\n",
    "    \n",
    "2. **Implémentez une chaine de traitement qui va :**\n",
    "    * Extraire les bordures des objets d'une image\n",
    "    * Nettoyer les portions/pixels non-utiles de l'image *edge* extraites (e.g. par ouverture)\n",
    "\n",
    "> Essayes votre pipeline sur une image bruitée comme `2_shapes.jpg`\n",
    "\n",
    "    \n",
    "3. **Implémentez les deux opérations suivantes et observez:**\n",
    "    1. **Top-Hat**: image - ouverture(image). \n",
    "> Cette opération isole les zones plus petites et de forme similaire à l'élément structurant et plus claires que leur entourage.\n",
    "    2. **Black-Hat**: fermeture(image) - image. \n",
    "> Cette opération isole les zones plus petites et de forme similaire à l'élément l'élément structurant et plus sombres que leur entourage.\n",
    "\n",
    "> Faites varier la taille de l'es et le nombre de passes, observez et commentez.    \n",
    "\n",
    "> <u>Astuce</u>: vous pouvez utiliser les méthodes spécifiques d'OpenCV pour comparer vos résultats :\n",
    "```Python\n",
    "morph = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, es)\n",
    "morph = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, es)\n",
    "```\n",
    "    \n",
    "4. **En partant de l'image N&B des cellules (`9_cells.png`), essayez d'en extraire les contours les plus propres possibles (en utilisant des opérations morphologiques, pre ou post extraction de contours). Réappliquez les contours obtenus à l'image d'origine de sorte à les faire ressortir (amplifier leur luminosité).**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3_ATtybdX3c"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpb_yYCjdX3f"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.3 Hit-or-Miss</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEZomSGwdX3g"
   },
   "source": [
    "*The **Hit-or-miss transform** is an operation that detects a given configuration (or pattern) in a binary image, using the morphological erosion operator and a pair of disjoint structuring elements. The result of the hit-or-miss transform is the set of positions where the first structuring element fits in the foreground of the input image, and the second structuring element misses it completely.*\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/hamcrn.gif\">\n",
    "\n",
    "*Here, we use two structuring elements (say B1 and B2). We ask a simple question : does B1 fits the object while, simultaneously, B2 misses the object (i.e. fits the background) ? In other words, we are interested only in those pixels whose neighborhood exactly matches B1 while not matching B2 at the same time.*\n",
    "\n",
    "Mathématiquement, la transformée Hit-or-Miss est formalisée comme : $I' = I\\odot B=(I\\ominus B_1)\\cap (I^c\\ominus B_2)$\n",
    "\n",
    "Avec :\n",
    "* $B_1$ et $B_2$ sont éléments structurants **disjoints**, dont la combinaison donne $B$.\n",
    "* $I^c$ le complément de $I$ : ($I^c = 1 - I$)\n",
    "\n",
    "<img src=\"https://i1.wp.com/theailearner.com/wp-content/uploads/2019/07/hitmiss.png?w=759&ssl=1\">\n",
    "\n",
    "Contrairement aux opérations morphologiques précédentes, les *kernels* des H|M n'est plus binaire, mais trinaire:\n",
    "* 1 (blanc): il faut qu'il y ait 1 dans ce pixel\n",
    "* 0 (gris): on s'en fiche de ce qu'il y à dans ce pixel\n",
    "* -1 (noir): il faut qu'il y ait 0 dans ce pixel\n",
    "\n",
    "L'application de l'ES illustré donnerait :\n",
    "\n",
    "<img src=\"https://i2.wp.com/theailearner.com/wp-content/uploads/2019/07/hitormiss-1.png?w=748&ssl=1\">\n",
    "\n",
    "La transformation hit-or-miss est utilisée pour détecter des patterns spécifiques dans une image. Elle peut être vue comme une détection de **gradient (2D) orienté.**\n",
    "\n",
    "*The hit-or-miss transform has many applications in more complex morphological operations: it is being used to construct the thinning, thickening and convex hull operators*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUND7-08dX3h"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import skimage.morphology as skimorph\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()\n",
    "    \n",
    "def affichage_1x2(img1,img2):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    plt.subplot(122), plt.imshow(img2, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_q9fcubdX3k"
   },
   "source": [
    "##### Avec OpenCV:\n",
    "```Python\n",
    "morphed = cv2.morphologyEx(img, cv2.MORPH_HITMISS, es, iterations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518,
     "referenced_widgets": [
      "3551677f4d5443fbbace04fa569d2d5d",
      "04ffb22b61ee4377aa5556d05cc076ef",
      "87901c59009f41d1a192f95c8b1572f8",
      "d4d077d1b9d74becbd1ec4dd09840d68",
      "9bd61a01af6e469f8bc740cd291147ae",
      "f345cbc3e6034a049a74240ee04d6b9d",
      "8c91103ae21b4157a58988173126d36e",
      "2ca7f06f396f487d956ff5e9e9526cad",
      "a17982c5e2ea469f82c8088ef51d0b11",
      "6d8d7851406b4c4a90ab9fa9ae245fb9",
      "5f3e4a60323340078917d3774cd5d927",
      "6e8db12642634223aadf1d9bff8765b2",
      "28ceb336070a4cd098ca6353a69ac03a",
      "51c39734045445e4a0ecfb02513654b7",
      "16d536e2da16434a9487d645a62fe52c"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23463,
     "status": "ok",
     "timestamp": 1580202315101,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "JmSE8LUpdX3l",
    "outputId": "92846618-9e12-4f28-c08c-06b96f6e4ece",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pass_slider = widgets.IntSlider(min=1, max=10, step=1, value=1)\n",
    "resize_slider = widgets.FloatSlider(min=0.2, max=5.0, step=0.2, value=1)\n",
    "\n",
    "@interact\n",
    "def hit_and_miss(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], \n",
    "          invert=False, n_passages=pass_slider, size=resize_slider):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = np.array([[-1,-1,-1],[1,1,1],[0,0,0]], dtype=\"int\")\n",
    "    es = cv2.resize(es, None, fx=size, fy=size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # On morph\n",
    "    morphed = cv2.morphologyEx(img, cv2.MORPH_HITMISS, es, iterations=n_passages)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pstqBG8IdX3s"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.4 Thinning & Thickening</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsaLiblzdX3w"
   },
   "source": [
    "### II.4.a Thinning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQePWaf9dX3x"
   },
   "source": [
    "*__Thinning__ is used to thin the foreground region such that its extent and connectivity are preserved, producing a **topologically equivalent** image. Preserving extent means preserving the endpoints of a structure, whereas preserving connectivity can refer to either 4-connected or 8-connected lines.*\n",
    "\n",
    "*Pixel connectivity illustration:*\n",
    "\n",
    "<img src=\"https://images.deepai.org/converted-papers/1906.03366/images/Connectedness.jpg\" width=300>\n",
    "\n",
    "*Thinning is mostly used for producing skeletons (which serve as image descriptors), and for reducing the output of the edge detectors to a one-pixel thickness.*\n",
    "\n",
    "<img src=\"https://i0.wp.com/theailearner.com/wp-content/uploads/2019/07/thinresult.png?resize=1024%2C141\">\n",
    "\n",
    "Thinning can be formalized based on the Hit-or-Miss transform : $I\\otimes B = I - (I\\odot B)$\n",
    "\n",
    "*The choice of structuring element determines under what situations a foreground pixel will be set to background, and hence it determines the application for the thinning operation. The binary structuring elements used for thinning are of the extended type described under the hit-and-miss transform (i.e. they can contain both ones and zeros).*\n",
    "\n",
    "*The operator is normally applied repeatedly until it causes no further changes to the image (i.e. until convergence). Alternatively, in some applications, e.g. pruning, the operations may only be applied for a limited number of iterations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZkGnyMPMdX3y"
   },
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435,
     "referenced_widgets": [
      "4a4549eebfe74b78ae345a5c31b9daa2",
      "8d7dcf4a52de4782aacfcf49e22104b8",
      "0bf7744e2b8e46bfba5fd17fffe5f410",
      "bdcd8b5915c64ee0a0c92d010699e8c4",
      "51a97dae774042e9925e42f2f00321e7",
      "53a0cfca68384bd79095bda9096772aa",
      "05becd905e644db8b6985bbbf83ffc29",
      "2463d2a4efa14becab0e3a60a1ebf7ae",
      "92ef6a8ce0f64a4b8ec9bfc3e98f0836"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23382,
     "status": "ok",
     "timestamp": 1580202315104,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "9g71DLMzdX3z",
    "outputId": "40ac3c6f-f2a1-4303-dc01-7db974a5a8a3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def thinning(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.thin(img)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2orZZbKCdX34"
   },
   "source": [
    "#### Exemple en combinant érosions et dilatations (via OpenCV) sur une image générée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "1e540e7fd8a946008ffe02bf6d63ac95",
      "63cdbb1316ff42658ff12f1a805e5fd7",
      "b90798102ed5412b88505dc413d3c021",
      "c267a511fedb41569f98c684856b67f9",
      "5d01fdf0f2154d0a89166cbbf7ad16a4",
      "e2c5ca4f371c495199b5badf4d80d754"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23780,
     "status": "ok",
     "timestamp": 1580202315528,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "30XDxym1dX36",
    "outputId": "de2eca81-1b78-40c8-908e-231ed912fd38",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_text_image(size, text, thick=5):\n",
    "    img = np.zeros(size, dtype='uint8')\n",
    "    cv2.putText(img, text, org=(int(0.3*size[0]), int(0.3*size[1])), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=3, color=(255), thickness=thick, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "@interact\n",
    "def thinning2(thick=(2,20,2)):\n",
    "    \n",
    "    # Créons une image de démo\n",
    "    img = create_text_image((200,400), \"THICK\", thick)\n",
    "    img1 = img.copy()\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    #img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "    \n",
    "    # On créé l'élément structurant\n",
    "    es = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    \n",
    "    # Create an empty output image to hold values\n",
    "    morphed = np.zeros(img.shape, dtype='uint8')\n",
    "\n",
    "    # On morph\n",
    "    # Loop until erosion leads to an empty set\n",
    "    while (cv2.countNonZero(img1)!=0):\n",
    "        # Erosion\n",
    "        erode = cv2.erode(img1, es)\n",
    "        # Opening on eroded image\n",
    "        opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, es)\n",
    "        # Subtract these two\n",
    "        subset = erode - opening\n",
    "        # Union of all previous sets\n",
    "        morphed = cv2.bitwise_or(subset, morphed)\n",
    "        # Set the eroded image for next iteration\n",
    "        img1 = erode.copy()\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x3(img, es, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnLbc2WYdX39"
   },
   "source": [
    "### II.4.b Thickening:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjNud4pAdX3-"
   },
   "source": [
    "*__Thickening__ is a morphological operation that is used to grow selected regions of foreground pixels in binary images, somewhat like dilation or closing. It has several applications such as determining the approximate convex hull of a shape.*\n",
    "\n",
    "*The thickened image consists of the original image plus any additional foreground pixels switched on by the hit-and-miss transform.*\n",
    "\n",
    "*Thickening is the dual of thinning, i.e. thickening the foreground is equivalent to thinning the background.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bG50mOdodX3_"
   },
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    "\n",
    "1. **Générez de nouveaux ES comprenant des zones *hit* et/ou *miss*:**\n",
    "    1. Créez différents types d'éléments structurants (via numpy, ou via `cv2getStructuringElement()`) \n",
    "    2. Les sauvegarder sous forme d'images binaires dans le dossier `img/es` de votre TP pour pouvoir les réutiliser.\n",
    "    3. Les appliquer aux différentes images du TP et observez.\n",
    "    \n",
    "> <u>Astuces</u>:\n",
    "```python\n",
    "cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "```\n",
    "> Vous pouvez également vous servir de `cv2.resize(es, None, fx=rate, fy=rate, interpolation=cv2.INTER_NEAREST)` pour redimensionner des ES existants.\n",
    "    \n",
    "> Vous pouvez vous servir des méthodes suivantes pour convertir un ES du format image (0-255) au binaire (0-1):\n",
    "```python\n",
    "def i2b(f):\n",
    "    return np.where(f==0, 1, 0)\n",
    "def b2i(f):\n",
    "    return np.where(f==1, 0, 255)\n",
    "```\n",
    "    \n",
    "    \n",
    "2. **Appliquez la méthode de Thinning d'OpenCV aux différentes images du TP (`img/morpho/`), pour différentes formes d'élément structurant, et observez l'impact sur le type de squelette généré.**\n",
    "    \n",
    "    \n",
    "3. **Reprenez votre programme du `II.2` et tentez d'améliorer l'extraction de contours grace au Thinning.**\n",
    "\n",
    "    \n",
    "4. **Créez une image carrée à fond noir sur laquelle vous tracerez une grille de 5x5 lignes blanches de 1 pixel de large, équidistantes entre elles. Trouvez l'ES permettant d'extraire les intersections des traits horizontaux et verticaux de cette image.**\n",
    "    \n",
    "> <u>Astuce</u>: Pour dessiner une ligne\n",
    "```python\n",
    "cv2.line(img, pt1, pt2, color)\n",
    "```\n",
    "    \n",
    "    \n",
    "5. **[<u>Bonus</u>] A partir des intersections extraites précédemment, créez une liste contenant les coordonnées (x,y) des pixels blancs de l'image, et tracez des lignes entre les points alignés verticalement et horizontalement, de sorte à re-créer l'image d'origine.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz2Wp5KudX4A"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLMDYIHedX4D"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.5 Skeletonization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIab89XUdX4F"
   },
   "source": [
    "*__Skeletonization__ (or Medial axis transform) is a process for reducing foreground regions in a binary image to a skeletal remnant that largely preserves the extent and connectivity of the original region while throwing away most of the original foreground pixels.*\n",
    "\n",
    "<img src=\"http://zone.ni.com/images/reference/en-XX/help/372916T-01/binary_lskeleton01.gif\">\n",
    "\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_morphology_008.png\">\n",
    "\n",
    "*The skeleton can be produced in two main ways :*\n",
    "* _The first is to use some kind of **morphological thinning** that successively erodes away pixels from the boundary (while preserving the end points of line segments) until no more thinning is possible, at which point what is left approximates the skeleton._ \n",
    "* _The alternative method is to first calculate the **distance transform** of the image. The skeleton then lies along the singularities (i.e. creases or curvature discontinuities) in the distance transform._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_AN4QOrdX4G"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section :\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "from skimage.util import random_noise\n",
    "import skimage.morphology as skimorph\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns                                  # Librairie de visualisation avancée\n",
    "\n",
    "from matplotlib.pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'         # Améliorer la netteté des figures\n",
    "plt.rcParams[\"figure.figsize\"] = 12.8, 9.6\n",
    "\n",
    "import warnings                                        # \"Do not disturb\" mode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def affichage_1x3(img1, img2, img3, grid=True):\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    gs  = GridSpec(1, 3, width_ratios=[1, 0.4, 1])\n",
    "    display_axes = \"both\" if grid else \"none\"\n",
    "    \n",
    "    plt.subplot(gs[0]), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    \n",
    "    plt.subplot(gs[1]), plt.imshow(img2, cmap='gray', extent=(0, img2.shape[0], img2.shape[1], 0), origin='upper')\n",
    "    plt.title(\"ES\"), plt.locator_params(nbins=len(img2)), plt.grid(axis=display_axes, color='b', linewidth=1)\n",
    "    \n",
    "    plt.subplot(gs[2]), plt.imshow(img3, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()\n",
    "    \n",
    "def affichage_1x2(img1,img2):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img1, cmap='gray'), plt.title(\"Image\", color='b')\n",
    "    plt.subplot(122), plt.imshow(img2, cmap='gray'), plt.title(\"Resultat\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p57E3mxJdX4K"
   },
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453,
     "referenced_widgets": [
      "2d19b1700909479891d808b3fbe4467d",
      "73e31687c5db4b3ea26251a20238f042",
      "aa56b014f53b4760bf3457656d02f7e0",
      "61e7fd673bea49609b01a16f08ab7ab5",
      "22d84347ba604cd9b1d2cb855db88cce",
      "15e9a020d8694f87bc66a227eb065cc2",
      "c8bc46bbde1b4b85a31572b2a7ffb78c",
      "3f284efbf62a4575a04223e4065e774d",
      "953c23d6def248a092fd5d17b51ec51f"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24348,
     "status": "ok",
     "timestamp": 1580202316144,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "BxsoE6jUdX4L",
    "outputId": "d34c0b56-051b-4f8f-e8a5-5e701ca82d0a"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def skeletonize(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.skeletonize(img == 1)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)\n",
    "    \n",
    "    display(Markdown(\"**Consignes**: Observez les effets sur l'image de cellules, et sur leur inverse !\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnkxdmm5dX4P"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.6 Convex Hull</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlotWMqtdX4Q"
   },
   "source": [
    "*The **convex hull** is the set of pixels included in the smallest convex polygon that surround all white pixels in the input image.*\n",
    "\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_morphology_009.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bYvGp4uedX4R"
   },
   "source": [
    "#### Exemple via Skimage (module `morphology`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435,
     "referenced_widgets": [
      "6e4cc544b8d843549fefa444efbbfe83",
      "fb378230de7f4c6ab18d3aec5649eb14",
      "6a9313ba5a674932b1b17530ecebb893",
      "4da3796b2e574fc6adc95d4b62c22053",
      "17fe70e003f944d88e7cfe8fac80ad77",
      "8233599cb41d4fe0814f359ff6584bfd",
      "cbe1d1ccf1304b0bba8d16df3e763b57",
      "5d66863bf9eb46ea880ef8a4211835ec",
      "2e763961654949a3804734b0e376a592"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24719,
     "status": "ok",
     "timestamp": 1580202316555,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "YBeZ2xiTdX4X",
    "outputId": "945961f6-7d26-47f2-c1e0-ca7cdb37fc7f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def convex_hull(image=[f for f in os.listdir(morpho_path) if os.path.isfile(os.path.join(morpho_path, f))], invert=False):\n",
    "    \n",
    "    # Importation\n",
    "    img = Image.open(morpho_path + image).convert(\"L\")\n",
    "    \n",
    "    if invert:\n",
    "        img = ImageOps.invert(img)\n",
    "    \n",
    "    # Binarisation (0 & 1)\n",
    "    img = np.array(1.0 * (np.array(img) > 127), dtype=\"uint8\")\n",
    "\n",
    "    # On morph\n",
    "    morphed = skimorph.convex_hull_image(img == 1)\n",
    "\n",
    "    # On affiche\n",
    "    affichage_1x2(img, morphed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BC9E8hLmdX4d"
   },
   "source": [
    "### <span style=\"color:crimson\">**[<u>Exercice</u>]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    "    \n",
    "**Votre objectif lors de cet exercice sera de combiner les différents outils à votre disposition (manipulation de luminance, débruitage, opération morphologiques) afin de segmenter l'image des cellules le plus proprement possible.**\n",
    "    \n",
    "> <u>Astuce</u>: Vous pouvez soustraire / ajouter, ou combiner (and/or) les masques entre eux (ou encore les masques avec l'image d'origine) pour obtenir de nouvelles images plus propices à la segmentation, ou a l'application d'autres traitements.\n",
    "    \n",
    "**Pour cela, vous allez devoir :**\n",
    "\n",
    "1. **Pré-traiter et binariser l'image :**\n",
    "    * Inverser l'image (les cellules sont suposées être l'information à détecter)\n",
    "    * Modifiez la répartition de luminance / contraste de l'image de sorte à faciliter la binarisation (min-max, equ, log ...). Vous pouvez également manipuler les seuils de ces opérations pour obtenir un résultat favorable.\n",
    "    * Déterminer le seuil de binarisation/segmentation optimal pour l'objectif de l'exercice.\n",
    "    \n",
    "    \n",
    "2. **Nettoyage du masque obtenu afin de retirer le bruit du background (éléments n'étant pas des cellules)**\n",
    "    \n",
    "> <u>Astuce</u>: vous pouvez vous servir :\n",
    "* De `skimage.morphology.remove_small_objects` pour retirer les petits objets de l'image\n",
    "* Ou encore `skimage.morphology.binary_closing(img, disk(3))` qui permet de spécifier les ES plus aisément.\n",
    "    \n",
    "    \n",
    "3. **Superposez le masque final avec l'image d'origine afin de segmenter les cellules.**\n",
    "   \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FN4NvzPPdX4q"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttNsTsYrdX4v"
   },
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "***\n",
    "# Fin du TP3\n",
    "***\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MXGZQlkXdX3C",
    "AfnFWQvTdX3b"
   ],
   "name": "IP - TP3.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
