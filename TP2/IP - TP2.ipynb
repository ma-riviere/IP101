{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvEg8iGwuJ4J"
   },
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "<div style=\"text-align:center\"> \n",
    "\n",
    "***\n",
    "# <u>TP2:</u>\n",
    "# Manipulation de luminance et Histogrammes  \n",
    "    \n",
    "<p style=\"text-align: center; color:gray\"><i>@Author:</i> Marc-Aurèle Rivière</p>\n",
    "\n",
    "***\n",
    "</div> \n",
    "\n",
    "<u>**Plan:**</u>\n",
    "\n",
    "1. [**Quelques rappels**](#1): histogrammes, luminance, contraste et exposition\n",
    "2. [**Opérations linéaires sur la luminance**](#2): inversions, ajout/retrait, etirement, egalisation, egalisation adaptative\n",
    "3. [**Opérations non-linéaires sur la luminance**](#3): transformée logarithmique, transformée gamma\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nONshOr9uJ4O"
   },
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"1\">I. Quelques rappels</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEBq1tIZuJ4Q"
   },
   "source": [
    "Nous abordons ici les techniques de traitement d'images basées sur la modification d'histogrammes. \n",
    "Ces méthodes font partie de la classe des traitements dits **ponctuels** (*pixel-wise*): la valeur de chaque pixel est corrigée, et ce indépendamment des autres pixels.\n",
    "\n",
    "La manipulation d'histogrammes est un outil très important en traitement d'images, permettant d'ajuster la dynamique des niveaux de gris ou des couleurs dans une image afin de la rendre plus agréable visuellement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bf_XqH91uJ4S"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.1 Histogrammes</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdIYFzQRuJ4T"
   },
   "source": [
    "**L'histogramme d'une image numérique** est une courbe statistique représentant la répartition de ses pixels selon leur intensité. Pour une image en noir et blanc, il indique en abscisse le niveau de gris (entier entre 0 et 255) et en ordonnée, le nombre de pixels ayant cette valeur.\n",
    "\n",
    "Lorsque l'histogramme est normalisé (somme à 1), il indique en ordonnée la probabilité $p_i$ de trouver un pixel de niveau de gris $i$ dans l'image. L'histogramme normalisé peut être interprété comme une **distribution de probabilité**. L'intensité d'un pixel est alors vue comme une variable aléatoire discrète.\n",
    "\n",
    "\n",
    "Un **histogramme cumulé normalisé** calcule le pourcentage de pixels ayant une valeur inférieure à un niveau de gris donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4VuP69MuJ4X"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.2 Luminance</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPoVXjhUuJ4Y"
   },
   "source": [
    "Quelques notions et mots de vocabulaire:\n",
    "\n",
    "- La **luminance** (ou intensité) est une mesure physique qui fait référence à la quantité de lumière absolue émise par un objet (par unité de surface).\n",
    "- La **luminosité** est une mesure perceptive qui fait référence à la brillance perçue d'un objet par un observateur humain.\n",
    "- **Tons clairs et foncés** font référence à des couleurs ayant respectivement une luminance élevée et faible.\n",
    "\n",
    "Illustration:  \n",
    "\n",
    "![Histogramme](img/Illustrations/Histo.png)\n",
    "\n",
    "Cette distinction est nécessaire car la luminosité perçue dépends d'autres paramètres de la scène que l'objet lui-même.\n",
    "\n",
    "***\n",
    "#### **[Parenthèse]**\n",
    "\n",
    "Cela se remarque dans certaines illusions d'optique comme:  \n",
    "<img src=\"img/Illustrations/optical.png\" width=\"400\">\n",
    "\n",
    "Notre cerveau fait constamment des hypothèses sur les propriétés de notre monde, et ces a priori viennent influencer notre perception du monde.  \n",
    "Ici en l'occurence, ces a priori influencent la luminosité perçue alors que les deux dalles ont la même teinte et la même luminance : nos yeux reçoivent la même quantité de lumière des deux, mais le dessin est fait de de sorte à donner l'illusion que B est dans une zone d'ombre. Or, pour votre cerveau, la seule manière qu'un objet B dans une zone d'ombre soit aussi brillant qu'un objet A hors de l'ombre est que B doit naturellement être plus clair que A pour que, malgré l'ombre, il brille autant. Et il corrige l'information perçue selon cette hypothèse, résultant en l'illusion observée: A et B ont des couleurs différentes.\n",
    "\n",
    "Ce genre d'hypothèses représentent un avantage évolutif et se révèleront être généralement utiles pour formuler des jugements perceptifs corrects rapidement, dans le monde réel. Certaines sont innées, d'autres apprises par l'expérience, mais elles sont omni-présentes dans notre perception du monde. Elles interviennent de manière inconsciente pour optimiser notre prise de décision. Cependant, ce genre d'heuristiques perceptives nous induisent parfois en erreur, notamment lorsqu'elles sont mises à mal intentionnellement par des illusions d'optiques faites spécifiquement pour les mettre à défaut. C'est à ce moment là qu'on les remarque, et qu'on se rend compte de leur nature irrépressible: on à beau savoir que l'on est trompés, on ne peut rien y changer.\n",
    "\n",
    "> *Percevoir est une bataille constante entre ce que l'on voit et ce que l'on s'attends à voir.*\n",
    "\n",
    "#### **[Fin de la parenthèse]**\n",
    "***\n",
    "  \n",
    "Pour une image en **niveaux de gris**, l'information de luminance est directement donnée par la valeur de chaque pixel, qui représente une quantité de lumière transmise (on parle également d'intensité).\n",
    "\n",
    "Pour une image **RGB**, l'information de luminance est \"répartie\" dans les trois canaux de couleur, et doit être extraire pour que l'image RGB soit convertie en image de niveaux de gris : on parle de séparer les valeurs de **luminance** et de **chrominance**. Les informations de luminance et chrominance (qui représente l'information de couleur pure, sans luminance) sont mélangées dans les canaux RGB, mais peuvent être séparées par des filtres spécifiques.  \n",
    "<img src=\"img/Illustrations/tri.png\" width=\"600\">\n",
    "\n",
    "Par exemple, la fonction `convert(\"L\")` de Pillow converti une image couleur en calculant la valeur de luminance (L) de chaque pixel par la fonction suivante : `L = R * 0.299 + G * 0.587 + B * 0.114`\n",
    "\n",
    "**Remarque:** L'information de luminance de chaque pixel va influencer à quel point le pixel (de l'écran) qui affiche ce pixel (de l'image) sera illuminé, ce qui va influencer à son tour la luminosité perçue par la personne devant l'écran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLFd9FHEuJ4a"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.3 Contraste</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6B1XYUKYuJ4d"
   },
   "source": [
    "Le **contraste** est une propriété intrinsèque d'une image qui quantifie la différence de luminance entre les parties claires et sombres. Cette caractéristique nous donne une idée sur la dispersion/répartition de la luminance au sein de l'image : plus les valeurs de luminance des pixels de l'image se ressemblent, plus faible sera le contraste. A contrario, plus la luminance varie dans l'image, plus le contraste sera élevé.\n",
    "\n",
    "En général, une image peu contrastée est terne, tandis qu'une image trop contrastée est visuellement \"agressive\". Dans les deux cas, l'image manque de clarté car certains de ses détails seront peu, voire pas du tout, visibles.\n",
    "\n",
    "**Remarque:** C'est un indice de dispersion (de la distribution de la luminance des pixels --> l'histogramme), au même titre que l'écart type ou la variance indiquent la dispersion des valeurs autour de la moyenne dans une distribution.\n",
    "\n",
    "#### *Cas particuliers :*\n",
    "- Si l'ensemble des pixels ont la même valeur, le contraste sera nul.\n",
    "- Une image constituée uniquement de pixels noirs et blanc aura un contraste maximal.\n",
    "\n",
    "#### Au niveau de l'histogramme, le contraste se traduira par:\n",
    "- Un histogramme (de luminance) peu dispersé (centré autour de la valeur moyenne de luminance) pour les images à faible contraste: pas de grandes variations dans la luminance.\n",
    "- Un histogramme plus étendu / dispersé pour les images à fort contraste.   \n",
    "\n",
    " <img src=\"img/Illustrations/Hist5.png\">\n",
    " \n",
    " \n",
    "**Ajuster le contraste** d'une image à pour but d'harmoniser la distribution des niveaux de gris de l'image, de sorte que chaque niveau de l'histogramme (`[0, 255]`) contienne idéalement le même nombre de pixels. Les méthodes d'ajustement de contraste vont donc modifier la valeur de luminance des pixels de l'image de sorte à redistribuer la luminance de manière plus équitable entre les pixels.\n",
    "\n",
    "Par exemple, accentuer les différences de luminance en rendant les pixels sombres plus sombres et les pixels clairs plus clairs augmentera le contraste.\n",
    "\n",
    "Il existe plusieurs méthodes pour accomplir cet objectif, linéaires ou non-linéaires, appartenant toutes à la catégorie générale de ***histogram remapping***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxgLT22cuJ4h"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">I.4 Niveau d'exposition</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nttdr8sguJ4k"
   },
   "source": [
    "Une image **sur-exposée** et **sous-exposée** auront toutes deux un faible contraste:\n",
    "- La majeure partie des pixels auront une valeur de luminance élevée pour les images sur-exposées (*high-key*), donc la luminance moyenne sera élevée, et le contraste sera faible.\n",
    "- La majeure partie des pixels auront une valeur de luminance faible pour les images sous-exposées (*low-key*), donc la luminance moyenne sera faible, et le contraste sera faible.\n",
    "\n",
    "<u>Faible contraste:</u>   \n",
    "<img src=\"img/Illustrations/cray_low.jpg\" width=\"340\">\n",
    "<img src=\"img/Illustrations/liz_low.jpg\" width=\"300\">\n",
    "\n",
    "<u>Fort contraste:</u>  \n",
    "<img src=\"img/Illustrations/cray_high.jpg\" width=\"340\">\n",
    "<img src=\"img/Illustrations/liz_high.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onfxFnn2uJ4n"
   },
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"2\">II. Opérations linéaires sur la luminance</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADD_FTbiuJ4p"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.1 Inversion</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31Al57xmuJ4r"
   },
   "source": [
    "Une **image négative** est une image dont les couleurs ont été inversées par rapport à l'originale : \n",
    "- Le rouge devient cyan, le vert devient magenta, le bleu devient jaune et inversement.\n",
    "- Les régions sombres deviennent claires, le noir devient blanc.  \n",
    "\n",
    "Au niveau de la luminance, chaque valeur est remplacée par son inverse: $I' = 255 - I$\n",
    "\n",
    "**Exemples:**  \n",
    "<img src=\"img/Illustrations/neg.jpg\" height=\"400\">\n",
    "\n",
    "**Remarque:** L'histogramme d'une image inversée sera l'inverse de celui de l'image d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FK3_JEWZuJ4s"
   },
   "outputs": [],
   "source": [
    "# Code commun\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Affichons l'image d'origine, son inverse, et leurs histogrammes\n",
    "def affichage_inverse(img, imgInv):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "    ax = fig.add_subplot(2,2,1)\n",
    "    plt.imshow(img, \"gray\")\n",
    "    ax.set_title(\"Image\")\n",
    "    ax = fig.add_subplot(2,2,2)\n",
    "    plt.hist(img.ravel(), 256, [0,256])\n",
    "    ax.set_title(\"Histogramme de l'image\")\n",
    "\n",
    "    ax = fig.add_subplot(2,2,3)\n",
    "    plt.imshow(imgInv, \"gray\")\n",
    "    ax.set_title(\"Image inversée\")\n",
    "    ax = fig.add_subplot(2,2,4)\n",
    "    plt.hist(imgInv.ravel(), 256, [0,256])\n",
    "    ax.set_title(\"Histogramme de l'image inversée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eng4dasNuJ4y"
   },
   "source": [
    "#### Inversion d'images par opérations matricielles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez inverser une image (au format matriciel) de deux manières :\n",
    "```python\n",
    "imgInv = 255 - img\n",
    "imgInv = ~img\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3idu-2luJ40",
    "outputId": "bcdb17b7-add9-44b7-9b2b-535dc1e8b59e"
   },
   "outputs": [],
   "source": [
    "img = np.array(Image.open('img/lena.jpg').convert(\"L\"))\n",
    "\n",
    "# On inverse l'image\n",
    "imgInv = ~img\n",
    "\n",
    "affichage_inverse(img, imgInv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ul6VuJAuJ48"
   },
   "source": [
    "#### Inversion d'image via des méthodes spécifiques (Pillow):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AiBXvk2uJ4-"
   },
   "source": [
    "##### En niveaux de gris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kdc0976SuJ4_",
    "outputId": "6b941198-aad8-48a9-d3b4-b247a5e56e5a"
   },
   "outputs": [],
   "source": [
    "img = Image.open('img/lena.jpg').convert(\"L\")\n",
    "\n",
    "# On inverse l'image\n",
    "imgInv = ImageOps.invert(img)\n",
    "\n",
    "affichage_inverse(np.array(img), np.array(imgInv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHuvdaxGuJ5E"
   },
   "source": [
    "##### En couleur:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKRMjjUYuJ5G"
   },
   "source": [
    "### <span style=\"color:crimson\">**[Exercice]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **En utilisant la même méthode de Pillow, chargez une image de votre choix en couleur et inversez-là.**\n",
    "    \n",
    "    \n",
    "2. **Affichez l'image d'origine et son histogramme, ainsi que l'image modifiée et son histogramme.**\n",
    "    \n",
    "    \n",
    "3. **Séparez les canaux de l'image, inversez-les et refusionez-les.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jod2t4DOuJ5J"
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvnRmLKauJ5O"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.2 Ajout / retrait (constantes)</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lj3UjZk2uJ5Q"
   },
   "source": [
    "Ajouter (ou retirer) une quantité constante de luminance à l'image permet de faire varier son niveau d'exposition (mais pas son contraste, qui est défini comme l'écart / la dispersion des valeurs de luminance dans l'image).\n",
    "\n",
    "Les nouvelles valeurs de luminance seront définies par : $I' = I + c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaJn4kebuJ5R"
   },
   "source": [
    "### II.2.a Par manipulation direct de la matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhD0_iJjuJ5T"
   },
   "outputs": [],
   "source": [
    "# Pour cette section, nous allons utiliser Pillow (PIL) et son module Image pour lire notre image\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Importons notre image en niveaux de gris avec le module \"Image\" de \"PIL\"\n",
    "img = Image.open('img/lena.jpg').convert('L')\n",
    "# Convertissons la en array (matrice) Python\n",
    "img = np.array(img)\n",
    "\n",
    "# Définissons une fonction pour regrouper le code permettant d'afficher une image et son histogramme côte-à-côte:\n",
    "def image_et_histo(img, cmap=\"gray\"):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    plt.imshow(img, cmap)\n",
    "    ax.set_title(\"Image\")\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    plt.hist(np.array(img).ravel(), 256, [0,256])\n",
    "    ax.set_title(\"Histogramme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x33hClInuJ5Z",
    "outputId": "0665a2d7-0730-4465-8280-d2ef7c94c450"
   },
   "outputs": [],
   "source": [
    "# Affichons l'image chargée et son histogramme:\n",
    "image_et_histo(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNtyKeAnuJ5g"
   },
   "source": [
    "##### Passons à la manipulation:\n",
    "\n",
    "Pour modifier la luminance d'une image en **niveaux de gris** stockée sous format de matrice (```np.array```), il suffit de modifier la valeur de chaque pixel de la matrice.  \n",
    "On peut alors ajouter ou retirer une certaine valeur à tous les pixels de l'image, sans discrimination sur leur valeur initiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlfe0VBDuJ5h",
    "outputId": "8c49a37a-76a4-4037-8e0d-c0cc97de163f"
   },
   "outputs": [],
   "source": [
    "# Ajoutons 80 à tous les pixels de l'image, en vérifiant que la valeur ne va pas excéder les 255\n",
    "imgL = np.where((255 - img) >= 80, img + 80, 255)\n",
    "\n",
    "image_et_histo(imgL, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqFALaskuJ5m"
   },
   "source": [
    "##### Observations:\n",
    "\n",
    "**Sur l'image:** \n",
    "- Notre image a bien gagné en luminance, mais on a aussi perdu de nombreux détails dans les zones les plus claires.  \n",
    "- En effet les pixels de l’image d’origine qui avaient une valeur de luminance de 175 ou plus se retrouvent avec une valeur supérieure à 255 après l'ajout de 80.  \n",
    "- On perd donc en détails dans les hautes luminances à cause de cette opération. On parle d’écrêtage du signal (*clipping*) : les nuances de luminance qui existaient entre 175 et 255 sont perdues à jamais (perte d'information non réversible).\n",
    "\n",
    "**Sur l'histogramme**: \n",
    "- On remarque que plus aucun pixel ne semble avoir une valeur < 80.\n",
    "- On voit également qu'il y a une majorité de pixels ayant une valeur de 255 (à cause de l'écrêtage du signal mentionné au dessus).\n",
    "  * C'est à cause de la mise à l'échelle de l'histogramme qu'il apparait applatit : il y a énormément de pixels avec la valeur 255, du coup les autres quantités semblent dérisoires à côté. Pour remédier à ça, on peut retirer la valeur 255 de l'histogramme artificiellement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yctiNCjuJ5n",
    "outputId": "40380259-d434-46dd-818b-82e3c221a905"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "plt.imshow(imgL, \"gray\")\n",
    "ax.set_title(\"Image après le +80\")\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "plt.hist(np.array(img).ravel(), 256, [0,255])\n",
    "ax.set_title(\"Histogramme de l'image d'origine\")\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "plt.hist(np.array(imgL).ravel(), 255, [0,254])\n",
    "ax.set_title(\"Histogramme après le +80\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "df-iFpkNuJ5w"
   },
   "source": [
    "Ici, on voit mieux qui l'histogramme à bien été \"poussé\" vers la droite (vers les valeurs élevées de luminance), et que tous les pixels avec une valeur de 175 et plus dans l'histogramme d'origine (avant la modification de luminance) ont disparus : ils valent tous 255 maintenant, et ne sont plus affichés sur l'histogramme.  \n",
    "\n",
    "**Remarque:** En photographie, une image avec un histogramme trop décalé vers là droite est dite sur-exposée : un déséquilibre de contraste du faite que trop de lumière à été captée et peu de détails sont disponibles dans les tons sombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TN7GngQNuJ5x",
    "outputId": "42f18b25-789a-4714-d22d-e153dbc6277b"
   },
   "outputs": [],
   "source": [
    "# Retirons 80 à tous les pixels de l'image, en vérifiant que la valeur ne va pas passer sous 0\n",
    "imgD = np.where(img >= 80, img - 80, 0)\n",
    "\n",
    "# Affichons le résultat\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "ax = fig.add_subplot(1,3,1)\n",
    "plt.imshow(imgD, \"gray\")\n",
    "ax.set_title(\"Image après le -80\")\n",
    "ax = fig.add_subplot(1,3,2)\n",
    "plt.hist(np.array(img).ravel(), 256, [0,255])\n",
    "ax.set_title(\"Histogramme de l'image d'origine\")\n",
    "ax = fig.add_subplot(1,3,3)\n",
    "plt.hist(np.array(imgD).ravel(), 255, [1,255])\n",
    "ax.set_title(\"Histogramme après le -80\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QP3LRxNnuJ52"
   },
   "source": [
    "Même observations qu'avant, sauf que cette fois-ci l'histogramme à été poussé vers la gauche (valeurs de faible luminance), et que plus aucun pixel n'a de valeur supérieure à 175.\n",
    "\n",
    "On parle alors d'image sous-exposée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAnIyGgXuJ53"
   },
   "source": [
    "### II.2.b Via Pillow :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iukAGsauJ56"
   },
   "source": [
    "Pillow fournit un ensemble de méthodes permettant de manipuler une image aisément : le module ```ImageEnhancer```  \n",
    "Parmi l'ensemble des méthodes de ce [module](https://pillow.readthedocs.io/en/3.1.x/reference/ImageEnhance.html#PIL.ImageEnhance.Brightness), il y à la classe ```Brightness``` qui permet de manipuler la luminance d'une image chargée avec Pillow.\n",
    "\n",
    "Elle s'utilise de la manière suivante:\n",
    "```Python\n",
    "# On initialise \"l'enhancer\"\n",
    "enhancer = ImageEnhance.Brightness(img)\n",
    "# On applique une augmentation de 30% de luminance\n",
    "img2 = enhancer.enhance(1.3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZPP3EKquJ57"
   },
   "source": [
    "##### Sur une image en niveaux de gris :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNszCooauJ59",
    "outputId": "e8f606a6-e06e-4219-8819-b9ced2cb02eb"
   },
   "outputs": [],
   "source": [
    "# Exemple en niveaux de gris\n",
    "img = Image.open('img/lena.jpg').convert('L')\n",
    "\n",
    "# On créé \"l'enhancer\" et on applique une réduction de 40% de luminance\n",
    "img2 = ImageEnhance.Brightness(img).enhance(0.6)\n",
    "\n",
    "image_et_histo(img2, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q3UX-RxIuJ6B"
   },
   "source": [
    "#### Sur une image couleur:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7sakxs3uJ6C"
   },
   "source": [
    "Pillow propose une méthode (```ImageEnhance```) pour modifier la luminance d'une image couleur sans avoir à extraire l'information de luminance des valeurs RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yMeorrjuuJ6E",
    "outputId": "74f6813f-577d-4586-e94e-b5ff00806fb9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = Image.open('img/lena.jpg')\n",
    "\n",
    "# On créé \"l'enhancer\" et on applique une augmentation de 30% de luminosité\n",
    "img2 = ImageEnhance.Brightness(img).enhance(1.3)\n",
    "\n",
    "# Fonction d'affichage utilisant OpenCV pour calculer l'histogramme de l'image\n",
    "def image_et_histo2(img):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    hist = cv2.calcHist([np.array(img)],[0],None,[256],[0,255])\n",
    "    \n",
    "    plt.subplot(121), plt.imshow(img, cmap='gray'), plt.title(\"Image originale\", color='b')\n",
    "    plt.subplot(122), plt.plot(hist), plt.title(\"Histogramme de l'image originale\", color='b')\n",
    "    plt.show()\n",
    "\n",
    "image_et_histo2(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAnLnY9nuJ6I"
   },
   "source": [
    "### <span style=\"color:crimson\">**[Exercice]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Implémentez une fonction permettant d'ajouter une valeur constante de luminance à une image couleur.**\n",
    "\n",
    "<u>Astuce</u>: passez l'image couleur dans un espace colorimétrique permettant de modifier sa luminance globale sans avoir à séparer les canaux.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8NTXPIduJ6W",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtBZTq8wuJ6e"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.3 Etirement</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0YMo7N1uJ6f"
   },
   "source": [
    "**L'étirement de contraste**, aussi appelé **normalisation d'image**, est une **méthode d'amélioration d'image ponctuelle** dans le domaine spatial, permettant de corriger les défauts d’exposition d'une image (et donc son contraste) en **étirant son histogramme** pour étendre les valeurs de luminance (intensité) à tout l'intervalle disponible (généralement `[0,255]`).\n",
    "\n",
    "C'est une **opération linéaire de changement à l'échelle** (*re-scaling*), où la valeur de chaque pixel est remplacée par :   \n",
    "\n",
    "\\begin{equation*}\n",
    "I′(x,y) = (I'_\\max - I'_\\min) * \\dfrac{(I(x,y) − I_\\min)}{(I_\\max − I_\\min)} + I'_\\min\n",
    "\\end{equation*}\n",
    "\n",
    "avec :\n",
    "* $I(x,y)$ et $I′(x,y)$ les intensités du pixel de coordonnées (x,y) respectivement dans l'image mal exposée et la nouvelle image.\n",
    "* $I'_\\min$ et $I'_\\max$ les nouvelles intensitées minimales et maximales choisiées (généralement 0 et 255, respectivement)\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/9gIw6.png\" width=\"400\">\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/mOoAC.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjaQoy1FuJ6h"
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import ImageOps, Image\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Affichons l'image originale, modifiée, et leurs histogrames (*smoothed* via un KDE - Kernel Density Estimation)\n",
    "def affichage_2x2(img1, img2):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, \"gray\")\n",
    "    ax1.set_title(\"Image originale\")\n",
    "    ax2 = plt.subplot(222)\n",
    "    sns.kdeplot(np.array(img1).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,255], cut=0)\n",
    "    ax2.set_title(\"Histogramme (KDE) de l'original\")\n",
    "    \n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, \"gray\")\n",
    "    ax3.set_title(\"Image ajustée\")\n",
    "    ax4 = plt.subplot(224, sharex=ax2, sharey=ax2)\n",
    "    sns.kdeplot(np.array(img2).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,255], cut=0)\n",
    "    ax4.set_title(\"Histogramme (KDE) de l'image ajustée\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfhIpEtGuJ6l"
   },
   "source": [
    "#### Exemple avec `ImageOps.autocontrast` et un widdget interactif de selection d'image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 863,
     "status": "error",
     "timestamp": 1580073785732,
     "user": {
      "displayName": "Rivière Marc-Aurèle",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBNfjDm1Y0wcm0EDe7v_Sdi-WtWb5EtJA-TV9SO=s64",
      "userId": "04667194983314352464"
     },
     "user_tz": -60
    },
    "id": "ILHnXT9euJ6m",
    "outputId": "7a8f00ea-d915-4d43-d578-4282a94eb399",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def autocontrast(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))]):\n",
    "    img = Image.open('img/' + image).convert(\"L\")\n",
    "    \n",
    "    # Avec ImageOps.autocontrast\n",
    "    stretchAuto = ImageOps.autocontrast(img)\n",
    "    \n",
    "    # Affichage\n",
    "    affichage_2x2(img, stretchAuto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80Mt4QWVuJ6u"
   },
   "source": [
    "#### Exemple interactif avec `cv2.normalize` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljcz0pgmuJ6w",
    "outputId": "aa9114c0-a796-46e2-b24e-78a3588a348d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def stretch(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], \n",
    "                       beta_val=(0, 3, 0.1)):\n",
    "    \n",
    "    imgLC = cv2.imread('img/' + image, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # normalize float versions\n",
    "    imgNorm = cv2.normalize(imgLC, None, alpha=0, beta=beta_val, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "    # scale to uint8\n",
    "    imgNorm = np.clip(imgNorm, 0, 1)\n",
    "    imgNorm = (255 * imgNorm).astype(np.uint8)\n",
    "\n",
    "    # Affichage\n",
    "    affichage_2x2(cv2.cvtColor(imgLC, cv2.COLOR_BGR2RGB), cv2.cvtColor(imgNorm, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UaCyHqJuJ60"
   },
   "source": [
    "### <span style=\"color:crimson\">**[Exercice]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Complétez le code suivant pour implémenter un type particulier d'étirement d'histogramme: l'étirement *MinMax*.**\n",
    "\n",
    "Celui ci est défini par l'équation : $I′(x,y) = 255 * \\dfrac{(I(x,y) − I_\\min)}{(I_\\max − I_\\min)}$\n",
    "\n",
    "2. **Modifiez votre code pour l'appliquer à une image couleur.**\n",
    "\n",
    "<u>Astuces</u>:\n",
    "* Utilisez les fonctions `np.min` et `np.max` pour calculer le min et max d'une image\n",
    "* Passer l'image couleur en HSV pour pouvoir modifier sa luminance globale sans avoir à séparer les canaux.\n",
    "* Essayez d'utiliser la notation vectorielle (au lieu de boucles imbriquées) pour optimiser le temps de calcul.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BCu2Fh8zuJ61",
    "outputId": "8e632191-942f-4ac7-abdb-2b1c0336b0f0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n",
    "\n",
    "# Cette fonction prends une image et retourne sa version étirée minmax\n",
    "def apply_minmax(img):\n",
    "    \n",
    "    # TODO: code à compléter\n",
    "  \n",
    "    return minmax_img\n",
    "\n",
    "@interact\n",
    "def minmax(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))]):\n",
    "    imgLC = cv2.imread('img/' + image)\n",
    "    \n",
    "    # On applique la méthode d'autocontraste manuelle\n",
    "    img_stretch = apply_minmax(imgLC)\n",
    "\n",
    "    # Affichage\n",
    "    affichage_2x2_KDE(cv2.cvtColor(imgLC, cv2.COLOR_BGR2RGB), img_stretch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJIOJ0tYuJ66"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.4 Egalisation d'Histogramme</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nusTxNK0uJ69"
   },
   "source": [
    "**L'égalisation de l'histograme**  (*histogram equalization*) est une **méthode globale de normalisation** qui modifie la luminance de chaque pixel de l'image de sorte à ce que toutes les valeurs de luminance soient présentes en quantités relativement équivalentes.\n",
    "\n",
    "L’objectif de l’égalisation d’histogramme est de faire en sorte que l'histogramme post-égalisation soit le plus plat possible, et permet donc d'augmenter le contraste global de l'image en \"redistribuant\" la luminance dans l'image. Cela peut également s'exprimer par le fait de rendre l'histogramme cumulé (CDF) linéaire.\n",
    "\n",
    "\n",
    "<img src=\"http://www.sci.utah.edu/~acoste/uou/Image/project1/images/equalization.png\">\n",
    "\n",
    "<u>Remarque:</u> Des versions plus modernes de cette technique se basent sur plusieurs sous-histogrammes de l'image pour modifier le contraste de manière plus locale, au lieu de travailler directement sur le contraste global. On peut mentionner:\n",
    "* Adaptive Histogram Equalization (AHE)\n",
    "* Contrast Limiting Adaptive Histogram Equalization (CLAHE)\n",
    "* Multipeak Histogram Equalization (MPHE)\n",
    "* Multipurpose Beta Optimized Bihistogram Equalization (MBOBHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUQnENIauJ6_"
   },
   "outputs": [],
   "source": [
    "# Code utile pour cette section\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "Affiche dans une grille 2x3:\n",
    " * L'image d'origine, son histogramme (continu, transformé via un KDE [Kernel Density Estimator] Gaussien) et l'histogramme cumulé (CDF)\n",
    " * L'image modifiée, son histogramme (continu, transformé via un KDE) et l'histogramme cumulé (CDF)\n",
    "'''\n",
    "def affichage2x3(img1, img2, cs=\"gray\"):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    ax1 = plt.subplot(231)\n",
    "    ax1.imshow(img1, cs)\n",
    "    ax1.set_title(\"Image originale\")\n",
    "    ax2 = plt.subplot(232)\n",
    "    ax2 = sns.kdeplot(np.array(img1).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,255], cut=0)\n",
    "    ax2.set_title(\"Histogramme (KDE) de l'original\")\n",
    "    ax3 = plt.subplot(233)\n",
    "    ax3.hist(np.array(img1).ravel(), bins=256, density=True, histtype='stepfilled', cumulative=True, color='tab:orange', alpha=0.5)\n",
    "    ax3.set_title(\"CDF de l'original\")\n",
    "    \n",
    "    ax4 = plt.subplot(234)\n",
    "    ax4.imshow(img2, cs)\n",
    "    ax4.set_title(\"Image ajustée\")\n",
    "    ax5 = plt.subplot(235, sharey=ax2)\n",
    "    ax5 = sns.kdeplot(np.array(img2).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[1,254], cut=0)\n",
    "    ax5.set_title(\"Histogramme (KDE) de l'image ajustée\")\n",
    "    ax6 = plt.subplot(236)\n",
    "    ax6.hist(np.array(img2).ravel(), bins=256, density=True, histtype='stepfilled', cumulative=True, color='tab:orange', alpha=0.5)\n",
    "    ax6.set_title(\"CDF de l'image ajustée\")\n",
    "    \n",
    "'''\n",
    "Affiche dans une grille 2x2:\n",
    " * L'image d'origine, son histogramme (continu, transformé via un KDE) combiné avec l'histogramme cumulé (CDF)\n",
    " * L'image modifiée, son histogramme (continu, transformé via un KDE) et l'histogramme cumulé (CDF)\n",
    "'''\n",
    "def affichage2x2(img1, img2, cs=\"gray\"):\n",
    "    fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "    ax1 = plt.subplot(221)\n",
    "    ax1.imshow(img1, cs)\n",
    "    ax1.set_title(\"Image originale\")\n",
    "    ax2 = plt.subplot(222)\n",
    "    hist1 = np.array(img1).ravel()\n",
    "    ax2 = sns.kdeplot(hist1, shade=True, kernel=\"gau\", bw=\"scott\", clip=[0, 255], cut=0)\n",
    "    ax2bis = ax2.twinx()\n",
    "    ax2bis = plt.hist(hist1, density=True, cumulative=1, histtype='step', bins=256, color='tab:orange')\n",
    "    ax2.set_title(\"KDE & CDF de l'original\")\n",
    "\n",
    "    ax3 = plt.subplot(223)\n",
    "    ax3.imshow(img2, cs)\n",
    "    ax3.set_title(\"Image ajustée\")\n",
    "    ax4 = plt.subplot(224, sharey=ax2)\n",
    "    hist2 = np.array(img2).ravel()\n",
    "    ax4 = sns.kdeplot(hist2, shade=True, kernel=\"gau\", bw=\"scott\", clip=[0, 255], cut=0)\n",
    "    ax42 = ax4.twinx()\n",
    "    ax42 = plt.hist(hist2, density=True, cumulative=1, histtype='step', bins=256, color='tab:orange')\n",
    "    ax4.set_title(\"KDE & CDF de l'image ajustée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QExBAYVRuJ7F"
   },
   "source": [
    "#### Ajustement de contraste avec la méthode `ImageEnhance.Contrast` de Pillow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "My5fJUpuuJ7G",
    "outputId": "1f631040-11fc-4999-f6ac-def1cb87e9bc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def enhance_contrast(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], value=(0,5,0.2)):\n",
    "    img = Image.open('img/' + image)\n",
    "\n",
    "    # On créé \"l'enhancer\" et on applique un rehaussement de $value$ % de contraste\n",
    "    img_hc = ImageEnhance.Contrast(img).enhance(value)\n",
    "\n",
    "    affichage2x3(img, img_hc, \"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_-wGr8tuJ7K"
   },
   "source": [
    "####  Egalisation d'histogramme avec `ImageOps.equalize` de Pillow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g98cElcLuJ7O",
    "outputId": "60859a72-2800-47da-ba70-f8e52286c645",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def equalize(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))]):\n",
    "    img = Image.open('img/' + image)\n",
    "\n",
    "    img_equ = ImageOps.equalize(img)\n",
    "\n",
    "    affichage2x3(img, img_equ, \"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFCLQKs7uJ7S"
   },
   "source": [
    "#### Egalisation d'histogramme d'image N&B avec `cv2.equalizeHist` d'OpenCV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4rN2pS8uJ7U",
    "outputId": "64cbe42b-2be1-48a3-862f-8e780895fd3c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def equalize(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))]):\n",
    "    img = cv2.imread('img/' + image, 0)\n",
    "\n",
    "    equ = cv2.equalizeHist(img)\n",
    "\n",
    "    affichage2x2(img, equ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5SFo0NpuJ7Y"
   },
   "source": [
    "On peut voir qu'après égalisation, l'histogramme est à la fois plus étendu et plus plat, et le cdf augmente linéairement.   \n",
    "Visuellement, le contraste des images à été amélioré: les zones sombres sont devenues plus sombres, et les zones claires plus claires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n42FzHBHuJ7a"
   },
   "source": [
    "####  Egalisation d'histogramme d'image couleur avec OpenCV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0r4k1j6uJ7h"
   },
   "source": [
    "### <span style=\"color:crimson\">**[Exercice]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Rédigez un programme interactif qui permet de :**\n",
    "    * Choisir une image avec un menu déroulant\n",
    "    * Faire varier son niveau d'exposition avec un curseur\n",
    "    * Choisir une méthode d'ajustement de contraste (stretching / equalization) par menu déroulant et l'appliquer.\n",
    "    * Affiche les résultats sous forme d'une grille 2x2   \n",
    "\n",
    "    \n",
    "2. **Implémentez une méthode permettant d'égaliser une image RGB en égalisant chacun des canaux séparément et l'ajouter aux choix de votre programme.**\n",
    "\n",
    "    \n",
    "3. **Implémentez une méthode permettant d'égaliser une image couleur en la transposant dans un espace colorimétrique ou la valeur de luminance globale peut être modifiée directement.**\n",
    "\n",
    "<u>Astuces</u>: vous pouvez utiliser la notation vectorielle pour faciliter votre code :\n",
    "``` Python\n",
    "imgYUV[:,:,0] = cv2.equalizeHist(imgYUV[:,:,0])\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DECyCmAuJ7i",
    "outputId": "e7f63f31-8e78-4125-d361-808b7dc202cf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n",
    "\n",
    "# Cette fonction prends une image RGB et égalise chaque canal séparément\n",
    "def equ_canaux(img):\n",
    "    \n",
    "    # TODO: code à compléter\n",
    "\n",
    "    return equ\n",
    "\n",
    "# Cette fonction prends une image couleur et égalise sa luminance globale\n",
    "def equ_global(img):\n",
    "    \n",
    "    # TODO: code à compléter\n",
    "\n",
    "    return equ\n",
    "\n",
    "# Fonction principale (qui permet l'interaction via les widgets de IPython)\n",
    "@interact\n",
    "def equ_interactif():\n",
    "    \n",
    "    # TODO: code à compléter\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HqHgvrduJ7m"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">II.5 Adaptative Histogram Equalization (AHE)</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbZHA3-nuJ7n"
   },
   "source": [
    "Parfois, dû à de grandes différences d'illumination entre différentes régions d'une même image, appliquer une égalisation globale de l'histogramme va améliorer le contraste de certaines régions, mais empirer celui d'autres.\n",
    "\n",
    "*Exemple:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1sqdn14uJ7o",
    "outputId": "309fc64d-ef5a-43b6-efc6-05d79565f816"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "img = cv2.imread('img/tsukuba.jpg', 0)\n",
    "equ = cv2.equalizeHist(img)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121), plt.imshow(img, \"gray\"), plt.title(\"Image originale\")\n",
    "plt.subplot(122), plt.imshow(equ, \"gray\"), plt.title(\"Image egalisée\")\n",
    "plt.show()\n",
    "\n",
    "display(Markdown(\"Ici, on remarque que le contraste de l'étagère (*background*) \" \n",
    "                 \"est améliorée, mais celui du mannequin (*foreground*) s'est détérioré.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0s4tgacuJ7r"
   },
   "source": [
    "**L'égalisation adaptative (AHE)** tente de remédier à ce problème découpant l'image en un **ensemble de sous-régions qui seront égalisées séparément**: on passe d'une égalisation globale à une **égalisation loacale** qui sera donc (potentiellement) plus respectueuse des variations locales de contraste dans l'image.\n",
    "\n",
    "Cependant, l'AHE \"simple\" à tendance à amplifier le bruit dans les régions relativement homogènes de l'image (là où la majorité des pixels ont des valeurs de luminance similaires, entrainant un pic important sur l'histogramme).\n",
    "\n",
    "**Contrast Limiting AHE (CLAHE)** est une extension de l'AHE qui permet de remédier à ce problème grâce au *clipping*.    \n",
    "L'algorithme fonctionne de la manière suivante:\n",
    "* Découpe l'image en une grille de `(n*n)` régions et calcule l'histogramme de chaque région.\n",
    "* *Clipping:* si une ou des valeurs d'intensité sont trop représentées (fréquence > seuil), une partie des pixels ayant ces luminances sont redistribués uniformément (seront réaffectés une nouvelle valeur de luminance).\n",
    "* L'histogramme (éventuellement tronqué) de chaque sous-région est égalisé.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Clahe-redist.svg/600px-Clahe-redist.svg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d88266ff37544641835733e205280d05"
     ]
    },
    "colab_type": "code",
    "id": "Vf3V31kEuJ7t",
    "outputId": "48d6eb9b-95c8-420c-c9c2-15dfaed0973b"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "@interact\n",
    "def clahe(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))], seuil_clip=(0, 1, 0.1), grid_size=(1,10,1)):\n",
    "    img = cv2.imread('img/' + image, 0)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=seuil_clip, tileGridSize=(grid_size,grid_size))\n",
    "    img_clahe = clahe.apply(img)\n",
    "\n",
    "    affichage2x2(img, img_clahe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5UITM8-IuJ70"
   },
   "source": [
    "# <span style=\"color: green;text-decoration: underline\" id=\"3\">III. Opérations non-linéaires sur la luminance</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzR8Fu7LuJ71"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">III.1 Transformée logarithmique</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOCB-Z0DuJ72"
   },
   "source": [
    "La **transformation logarithmique** consiste à remplacer la luminance de chaque pixel par son logarithme. Elle permet d'ajuster les valeurs de luminance (et donc le contraste) de manière non-linéaire: les pixels sombres seront réhaussés bien plus que les pixels clairs. \n",
    "\n",
    "Cette transformation va donc transposer une gamme étroite d'intensités (faibles / sombres) de l'image d'entrée sur une gamme plus importante dans l'image de sortie, ce qui augmentera le contraste (et donc la quantité de détails visibles) spécifiquement dans les zones sombres.\n",
    "\n",
    "\\begin{equation*}\n",
    "I'(x,y) = T(r) = c * log(1 + I(x,y))\n",
    "\\end{equation*}\n",
    "\n",
    "Avec:\n",
    "* $I(x,y)$ et $I'(x,y)$ la valeur de luminance d'un pixel d'entrée et de sortie, respectivement.\n",
    "* $c$ une constante de mise à l'échelle, définie par: $c = \\dfrac{255}{log(1 + I_\\max)}$\n",
    "\n",
    "La formule peut être résumée en :\n",
    "\n",
    "\\begin{equation*}\n",
    "I'(x,y) = 255 * \\dfrac{log(1 + I(x,y))}{log(1 + I_\\max)}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2llsfkqMuJ73",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Code utile pour cette section\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "\n",
    "def affichage2x3(img1, img2, cs=\"gray\"):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    ax1 = plt.subplot(231)\n",
    "    ax1.imshow(img1, cs)\n",
    "    ax1.set_title(\"Image égalisée\")\n",
    "    ax2 = plt.subplot(232)\n",
    "    ax2 = sns.kdeplot(np.array(img1).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[0,255], cut=0)\n",
    "    ax2.set_title(\"Histogramme (KDE) de égalisée\")\n",
    "    ax3 = plt.subplot(233)\n",
    "    ax3.hist(np.array(img1).ravel(), bins=256, density=True, histtype='stepfilled', cumulative=True, color='tab:orange', alpha=0.5)\n",
    "    ax3.set_title(\"CDF de l'image égalisée\")\n",
    "    \n",
    "    ax4 = plt.subplot(234)\n",
    "    ax4.imshow(img2, cs)\n",
    "    ax4.set_title(\"Image log-transformée\")\n",
    "    ax5 = plt.subplot(235, sharey=ax2)\n",
    "    ax5 = sns.kdeplot(np.array(img2).ravel(), shade=True, kernel=\"gau\", bw=\"scott\", clip=[1,254], cut=0)\n",
    "    ax5.set_title(\"Histogramme (KDE) de l'image log-transformée\")\n",
    "    ax6 = plt.subplot(236)\n",
    "    ax6.hist(np.array(img2).ravel(), bins=256, density=True, histtype='stepfilled', cumulative=True, color='tab:orange', alpha=0.5)\n",
    "    ax6.set_title(\"CDF de l'image log transformée\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b7a6f773072c474dac996256c752e2fe"
     ]
    },
    "colab_type": "code",
    "id": "nkTP2fkwuJ78",
    "outputId": "7a5c8584-3857-4583-81a0-6c9c809a0cc6"
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def log_transform(image=[f for f in os.listdir(\"img/\") if os.path.isfile(os.path.join(\"img/\", f))]):\n",
    "    img = cv2.imread('img/' + image, 0)\n",
    "    img = cv2.equalizeHist(img)\n",
    "\n",
    "    img_log = 255 * (np.log(img + 1)/(np.log(1 + np.max(img))))\n",
    "    img_log = np.array(img_log, dtype=\"uint8\")\n",
    "    \n",
    "    affichage2x3(img, img_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rzuQv_3uJ8B"
   },
   "source": [
    "## <span style=\"color: DodgerBlue;text-decoration: underline\">III.2 Transformée Gamma</span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZUSK7bwuJ8E"
   },
   "source": [
    "La **correction Gamma (ou *Power Law transform*)** consiste à remplacer la luminance de chaque pixel par une puissance (gamma) de sa valeur. Cette transformation, souvent appliquée nativement par les écrans (avec différentes valeurs de gamma), permet de mieux faire correspondre les variations de luminance du capteur (qui à capturé l'image) a notre perception.\n",
    "\n",
    "*The reason we apply gamma correction is because our eyes perceive color and luminance differently than the sensors in a digital camera. When a sensor on a digital camera picks up twice the amount of photons, the signal is doubled. However, our eyes do not work like this. Instead, our eyes perceive \"double the amount of light\" as only a fraction brighter. Thus, while a digital camera has a linear relationship between brightness our eyes have a non-linear relationship. In order to account for this relationship we apply gamma correction.*\n",
    "\n",
    "La correction gamma est décrite par l'équation suivante:\n",
    "\n",
    "\\begin{equation*}\n",
    "I'(x,y) = T(r) = c * \\left( \\frac{I(x,y)}{c} \\right)^\\gamma\n",
    "\\end{equation*}\n",
    "\n",
    "Avec:\n",
    "* $I(x,y)$ et $I'(x,y)$ la valeur de luminance d'un pixel d'entrée et de sortie, respectivement.\n",
    "* $c$ une constante de mise à l'échelle, généralement égale à 255.\n",
    "\n",
    "On observera :\n",
    "- `Gamma = 1` : image inchangée\n",
    "- `Gamma < 1` : image assombrie\n",
    "- `Gamma > 1` : image éclaircie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OQq-iGmuJ8G"
   },
   "source": [
    "### <span style=\"color:crimson\">**[Exercice]** A vous de jouer:</span>\n",
    "***\n",
    "<div style=\"color:DarkSlateBlue\">  \n",
    " \n",
    "1. **Implémentez le code de la correction gamma.**\n",
    "    \n",
    "    \n",
    "2. **Rédigez un programme interactif qui permet de :**\n",
    "    * Choisir une image avec un menu déroulant\n",
    "    * Choisir la valeur du paramère $\\gamma$ (de la correction éponyme) via un slider.\n",
    "    * Affiche les résultats sous forme d'une grille 2x2: (Image log, Hist log + CDF) et (Image gamma, Hist gamma + CDF)\n",
    "    * Afficher le tracé de l'équation de transformation appliquée (mise à jour selon la valeur de $\\gamma$)\n",
    "\n",
    "\n",
    "<u>Astuces</u>: vous pouvez utiliser la notation vectorielle pour faciliter votre code :\n",
    "``` Python\n",
    "x = np.linspace(0,255,100)\n",
    "y = # TODO: Equation de la courbe\n",
    "plt.plot(x, y)\n",
    "```\n",
    "    \n",
    "3. **Modifiez votre code de sorte à ce qu'il soit appliquable à une image couleur.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QykKaFXquJ8I",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# > Emplacement exercice <\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3fBS5XvuJ8O"
   },
   "source": [
    "<div style=\"color:Navy\"> \n",
    "\n",
    "***\n",
    "# Fin du TP2\n",
    "***\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eng4dasNuJ4y",
    "6Ul6VuJAuJ48",
    "mKRMjjUYuJ5G",
    "CaJn4kebuJ5R",
    "UAnIyGgXuJ53",
    "q3UX-RxIuJ6B",
    "qAnLnY9nuJ6I",
    "80Mt4QWVuJ6u",
    "8UaCyHqJuJ60",
    "QExBAYVRuJ7F",
    "U_-wGr8tuJ7K",
    "SFCLQKs7uJ7S",
    "n42FzHBHuJ7a",
    "f0r4k1j6uJ7h",
    "8OQq-iGmuJ8G"
   ],
   "name": "IP101 - TP2.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
